{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Tarea_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartinVIllesca/CC6205-Procesamiento-de-Lenguaje-Natural/blob/master/Tarea2/Tarea_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z0tyIsliieNr"
      },
      "source": [
        "# Tarea 2 - Named Entity Recognition\n",
        "\n",
        "----------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T15:21:15.416464Z",
          "start_time": "2020-06-22T15:21:15.411478Z"
        },
        "colab_type": "text",
        "id": "X3QUWWoWaSE3"
      },
      "source": [
        "- **Nombre:** Martín Valderrama, Jou-Hui Ho\n",
        "\n",
        "- **Usuario o nombre de equipo en Codalab:** pibjou\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W_dxGEs3iiau"
      },
      "source": [
        "\n",
        "## Introducción a la tarea\n",
        "\n",
        "### Objetivo\n",
        "\n",
        "\n",
        "El objetivo de esta tarea es resolver una de las tasks mas importantes de Sequence Labelling: [Named Entity Recognition (NER)](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf). \n",
        "\n",
        "\n",
        "Esperamos que (por lo menos) utilizen Redes Neuronales Recurrentes (RNN) para resolverla. Nuevamente, hay total libertad para utilizar software y los modelos que deseen, siempre y cuando estos no traigan los modelos ya implementados (como el caso de spacy).\n",
        "\n",
        "\n",
        "**Named Entity Recognition (NER)**\n",
        "\n",
        "Esta tarea consiste en localizar y clasificar los tokens de una oración que representen entidades nombradas. Es decir, tokens que simbolicen (1) **personas**, (2) **organizaciones**, (3) **lugares** y (4) **adjetivos, eventos y otras entidades que no entren en las categorías anteriores** deberán ser taggeados como (1) **PER**, (2) **ORG**, (3) **LOC** y (4) **MISC** respectivamente. Adicionalmente, dado que existen entidades representadas en más de un token (como La Serena), se utiliza la notación BIO como prefijo al tag: Beginning, Inside, Outside. Es decir, si encuentro una entidad, el primer token etiquetado será precedido por B, el segundo por I y los n restantes por I. Por otra parte, si el token no representa ninguna entidad nombrada, se representa por O. Un ejemplo de esto es:\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "```\n",
        "Felipe B-PER\n",
        "Bravo I-PER\n",
        "es O\n",
        "el O\n",
        "profesor O\n",
        "de O\n",
        "PLN B-MISC\n",
        "de O\n",
        "la O\n",
        "Universidad B-ORG\n",
        "de I-ORG\n",
        "Chile I-ORG\n",
        ". O\n",
        "```\n",
        "\n",
        "Estos links son los más indicados para comenzar:\n",
        "\n",
        "-  [Tagging, and Hidden Markov Models ](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf) (slides by Michael Collins), [notes](http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf), [video 1](https://youtu.be/-ngfOZz8yK0), [video 2](https://youtu.be/PLoLKQwkONw), [video 3](https://youtu.be/aaa5Qoi8Vco), [video 4](https://youtu.be/4pKWIDkF_6Y)       \n",
        "-  [Recurrent Neural Networks](slides/NLP-RNN.pdf) | [video 1](https://youtu.be/BmhjUkzz3nk), [video 2](https://youtu.be/z43YFR1iIvk), [video 3](https://youtu.be/7L5JxQdwNJk)\n",
        "\n",
        "\n",
        "Recuerden que todo el material se encuentra disponible en el [github del curso](https://github.com/dccuchile/CC6205)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V5BBxJWQaSE-"
      },
      "source": [
        "**Link a la competencia:  https://competitions.codalab.org/competitions/25302?secret_key=690406c7-b3b0-4092-8694-d08d7991ca94**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4HfZqQ-_aSFE"
      },
      "source": [
        "### Reporte\n",
        "\n",
        "Este debe cumplir la siguiente estructura:\n",
        "\n",
        "1.\t**Introducción**: Presentar brevemente el problema a resolver, los modelos utilizados en el desarrollo de la tarea y conclusiones obtenidas. (0.5 Puntos)\n",
        "\n",
        "2.\t**Modelos**: Describir brevemente los modelos, métodos y hiperparámetros utilizados. (1.0 puntos)\n",
        "\n",
        "4.\t**Métricas de evaluación**: Describir las métricas utilizadas en la evaluación indicando que miden y cuál es su interpretación en este problema en particular. (0.5 puntos)\n",
        "\n",
        "5.\t**Experimentos**: Reportar todos sus experimentos y código en esta sección. Comparar los resultados obtenidos utilizando diferentes modelos. ¡Es vital haber realizado varios experimentos para sacar una buena nota! (3.0 puntos)\n",
        "\n",
        "6.\t**Conclusiones**: Discutir resultados, proponer trabajo futuro. (1.0 punto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f7X2FruyaSFG"
      },
      "source": [
        "\n",
        "-----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PzQlYlmGaSFH"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UbA1EmhCaSFI"
      },
      "source": [
        "## Modelos \n",
        "\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AaVhZ5iaaSFK"
      },
      "source": [
        "## Métricas de evaluación\n",
        "\n",
        "- **Precision:** ...\n",
        "- **Recall:** ...\n",
        "- **F1 score:** ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T15:44:52.175773Z",
          "start_time": "2020-06-22T15:44:52.172782Z"
        },
        "colab_type": "text",
        "id": "uFM-wNt8aSFM"
      },
      "source": [
        "## Experimentos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LMgKjfYC_Go-"
      },
      "source": [
        "###  Carga de datos y Preprocesamiento\n",
        "\n",
        "El proceso será el siguiente: \n",
        "\n",
        "1. Descargar los datos desde github y examinarlos.\n",
        "2. Definir los campos (`fields`) que cargaremos desde los archivos.\n",
        "3. Cargar los datasets.\n",
        "4. Crear el vocabulario.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:24:52.392908Z",
          "start_time": "2020-06-23T22:24:50.641641Z"
        },
        "colab_type": "code",
        "id": "27csY87GaSFO",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "4f3806d6-c24c-4268-fe20-91782773daa3"
      },
      "source": [
        "# Instalar torchtext (en codalab) - Descomentar.\n",
        "!pip3 install --upgrade torchtext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61kB 3.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 24.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 15.5MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 13.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 12.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 9.5MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 8.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 8.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 8.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92kB 8.3MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 112kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 122kB 8.5MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▎                           | 143kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 153kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▉                           | 163kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 174kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 184kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 194kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 204kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 215kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 225kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 235kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 245kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 256kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 266kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 276kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 286kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 296kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 307kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 317kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 327kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 337kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 348kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 358kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 368kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 378kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 389kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 399kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 409kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 419kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 430kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 440kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 450kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 460kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 471kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 481kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 491kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 501kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 512kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 522kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 532kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 542kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 552kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 563kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 573kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 583kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 593kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 604kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 614kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 624kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 634kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 645kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 655kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 665kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 675kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 686kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 696kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 706kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 716kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 727kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 737kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 747kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 757kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 768kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 778kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 788kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 798kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 808kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 819kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 829kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 839kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 849kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 860kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 870kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 880kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 890kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 901kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 911kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 921kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 931kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 942kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 952kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 962kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 972kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 983kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 993kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.5.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.10)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.91 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:24:53.086354Z",
          "start_time": "2020-06-23T22:24:52.394902Z"
        },
        "colab_type": "code",
        "id": "ng7wRGEyawjM",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data, datasets\n",
        "\n",
        "# Garantizar reproducibilidad \n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:49.789218Z",
          "start_time": "2020-06-23T22:24:53.088871Z"
        },
        "colab_type": "code",
        "id": "lbT0g_kC18Jb",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/Data/train_NER_esp.txt -nc # Dataset de Entrenamiento\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/Data/val_NER_esp.txt -nc    # Dataset de Validación (Para probar y ajustar el modelo)\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/Data/test_NER_esp.txt -nc  # Dataset de la Competencia. Estos datos solo contienen los tokens. ¡¡SON LOS QUE DEBEN SER PREDICHOS!!"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uMud7YGMBZvg"
      },
      "source": [
        "####  Fields\n",
        "\n",
        "Un `field`:\n",
        "\n",
        "* Define un tipo de datos junto con instrucciones para convertir el texto a Tensor.\n",
        "* Contiene un objeto `Vocab` que contiene el vocabulario (palabras posibles que puede tomar ese campo).\n",
        "* Contiene otros parámetros relacionados con la forma en que se debe numericalizar un tipo de datos, como un método de tokenización y el tipo de Tensor que se debe producir.\n",
        "\n",
        "\n",
        "Analizemos el siguiente cuadro el cual contiene un ejemplo cualquiera de entrenamiento:\n",
        "\n",
        "\n",
        "```\n",
        "El O\n",
        "Abogado B-PER\n",
        "General I-PER\n",
        "del I-PER\n",
        "Estado I-PER\n",
        ", O\n",
        "Daryl B-PER\n",
        "Williams I-PER\n",
        "```\n",
        "\n",
        "Cada linea contiene una palabra y su clase. Para que `torchtext` pueda cargar estos datos, debemos definir como va a leer y separar los componentes de cada una de las lineas.\n",
        "Para esto, definiremos un field para cada uno de esos componentes: Las palabras (`TEXT`) y los NER_TAGS (`clase`).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:49.795126Z",
          "start_time": "2020-06-23T22:25:49.791108Z"
        },
        "colab_type": "code",
        "id": "3DcM_IjgCdzz",
        "colab": {}
      },
      "source": [
        "# Primer Field: TEXT. Representan los tokens de la secuencia\n",
        "TEXT = data.Field(lower=False) \n",
        "\n",
        "# Segundo Field: NER_TAGS. Representan los Tags asociados a cada palabra.\n",
        "NER_TAGS = data.Field(unk_token=None)\n",
        "\n",
        "fields = ((\"text\", TEXT), (\"nertags\", NER_TAGS))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xCKTJOdgC5eC"
      },
      "source": [
        "####  SequenceTaggingDataset\n",
        "\n",
        "`SequenceTaggingDataset` es una clase de torchtext diseñada para contener datasets de sequence labelling. \n",
        "Los ejemplos que se guarden en una instancia de estos serán arreglos de palabras pareados con sus respectivos tags.\n",
        "Por ejemplo, para Part-of-speech tagging:\n",
        "\n",
        "[I, love, PyTorch, .] estará pareado con [PRON, VERB, PROPN, PUNCT]\n",
        "\n",
        "\n",
        "La idea es que usando los fields que definimos antes, le indiquemos a la clase cómo cargar los datasets de prueba, validación y test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.294370Z",
          "start_time": "2020-06-23T22:25:49.797092Z"
        },
        "colab_type": "code",
        "id": "HsHdGml62J21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "23f282e7-eb69-4d88-bfc6-607e70d2fa7e"
      },
      "source": [
        "train_data, valid_data, test_data = datasets.SequenceTaggingDataset.splits(\n",
        "    path=\"./\",\n",
        "    train=\"train_NER_esp.txt\",\n",
        "    validation=\"val_NER_esp.txt\",\n",
        "    test=\"test_NER_esp.txt\",\n",
        "    fields=fields,\n",
        "    encoding=\"iso-8859-1\",\n",
        "    separator=\" \"\n",
        ")\n",
        "\n",
        "print(f\"Numero de ejemplos de entrenamiento: {len(train_data)}\")\n",
        "print(f\"Número de ejemplos de validación: {len(valid_data)}\")\n",
        "print(f\"Número de ejemplos de test (competencia): {len(test_data)}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de ejemplos de entrenamiento: 8323\n",
            "Número de ejemplos de validación: 1915\n",
            "Número de ejemplos de test (competencia): 1517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.317313Z",
          "start_time": "2020-06-23T22:25:50.303361Z"
        },
        "colab_type": "code",
        "id": "T023Ld4RaSF4",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "4610f5e3-7fd8-4d14-8b54-c803e0050559"
      },
      "source": [
        "# # Un ejemplo\n",
        "import random\n",
        "random_item_idx = random.randint(0, len(train_data))\n",
        "random_example = train_data.examples[random_item_idx]\n",
        "list(zip(random_example.text, random_example.nertags))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Wolff', 'B-PER'),\n",
              " (',', 'O'),\n",
              " ('ahora', 'O'),\n",
              " ('periodista', 'O'),\n",
              " ('en', 'O'),\n",
              " ('Argentina', 'B-LOC'),\n",
              " (',', 'O'),\n",
              " ('jugó', 'O'),\n",
              " ('con', 'O'),\n",
              " ('Del', 'B-PER'),\n",
              " ('Bosque', 'I-PER'),\n",
              " ('en', 'O'),\n",
              " ('los', 'O'),\n",
              " ('últimos', 'O'),\n",
              " ('años', 'O'),\n",
              " ('de', 'O'),\n",
              " ('los', 'O'),\n",
              " ('70', 'O'),\n",
              " ('en', 'O'),\n",
              " ('el', 'O'),\n",
              " ('Real', 'B-ORG'),\n",
              " ('Madrid', 'I-ORG'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2l05KYy5FSUy"
      },
      "source": [
        "#### Construir los vocabularios para el texto y las etiquetas\n",
        "\n",
        "Los vocabularios son los obbjetos que contienen todos los tokens (de entrenamiento) posibles para ambos fields.\n",
        "El siguiente paso consiste en construirlos. Para esto, hacemos uso del método `Field.build_vocab` sobre cada uno de nuestros `fields`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.445968Z",
          "start_time": "2020-06-23T22:25:50.320305Z"
        },
        "colab_type": "code",
        "id": "PBhp7WICiibL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "27609702-0145-47ee-b57b-aeafa708eaf6"
      },
      "source": [
        "TEXT.build_vocab(train_data)\n",
        "NER_TAGS.build_vocab(train_data)\n",
        "\n",
        "print(f\"Tokens únicos en TEXT: {len(TEXT.vocab)}\")\n",
        "print(f\"Tokens únicos en NER_TAGS: {len(NER_TAGS.vocab)}\")\n",
        "\n",
        "#Veamos las posibles etiquetas que hemos cargado:\n",
        "print(NER_TAGS.vocab.itos)\n",
        "\n",
        "# Tokens mas frecuentes\n",
        "TEXT.vocab.freqs.most_common(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokens únicos en TEXT: 26101\n",
            "Tokens únicos en NER_TAGS: 10\n",
            "['<pad>', 'O', 'B-ORG', 'I-ORG', 'B-LOC', 'B-PER', 'I-PER', 'I-MISC', 'B-MISC', 'I-LOC']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('de', 17657),\n",
              " (',', 14716),\n",
              " ('la', 9571),\n",
              " ('que', 7516),\n",
              " ('.', 7263),\n",
              " ('el', 6905),\n",
              " ('en', 6484),\n",
              " ('\"', 5691),\n",
              " ('y', 5336),\n",
              " ('a', 4304)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.479897Z",
          "start_time": "2020-06-23T22:25:50.475889Z"
        },
        "id": "3T6zXWK8zXxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seteamos algunas variables que nos serán de utilidad mas adelante...\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "PAD_TAG_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "O_TAG_IDX = NER_TAGS.vocab.stoi['O']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.490885Z",
          "start_time": "2020-06-23T22:25:50.481873Z"
        },
        "colab_type": "code",
        "id": "tuXOsbJUiibh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "48b78f94-1b5a-472a-80c7-379468d0d8b7"
      },
      "source": [
        "# Frecuencia de los Tags\n",
        "\n",
        "def tag_percentage(tag_counts):\n",
        "    \n",
        "    total_count = sum([count for tag, count in tag_counts])\n",
        "    tag_counts_percentages = [(tag, count, count/total_count) for tag, count in tag_counts]\n",
        "  \n",
        "    return tag_counts_percentages\n",
        "\n",
        "print(\"Tag Ocurrencia Porcentaje\\n\")\n",
        "\n",
        "for tag, count, percent in tag_percentage(NER_TAGS.vocab.freqs.most_common()):\n",
        "    print(f\"{tag}\\t{count}\\t{percent*100:4.1f}%\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tag Ocurrencia Porcentaje\n",
            "\n",
            "O\t231920\t87.6%\n",
            "B-ORG\t7390\t 2.8%\n",
            "I-ORG\t4992\t 1.9%\n",
            "B-LOC\t4913\t 1.9%\n",
            "B-PER\t4321\t 1.6%\n",
            "I-PER\t3903\t 1.5%\n",
            "I-MISC\t3212\t 1.2%\n",
            "B-MISC\t2173\t 0.8%\n",
            "I-LOC\t1891\t 0.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T21:44:17.730460Z",
          "start_time": "2020-06-22T21:44:17.724482Z"
        },
        "colab_type": "text",
        "id": "y4wPiydnaSGs"
      },
      "source": [
        "#### Configuramos pytorch y dividimos los datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.101455Z",
          "start_time": "2020-06-23T22:25:50.492843Z"
        },
        "colab_type": "code",
        "id": "uB7cwLWpaSGs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ead9ae8d-146a-4a7a-8aae-e0f619915dac"
      },
      "source": [
        "BATCH_SIZE = 16  # disminuir si hay problemas de ram.\n",
        "\n",
        "# Usar cuda si es que está disponible.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "# Dividir datos entre entrenamiento y test\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort=False,\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ISH58OP2Efn",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:54.515194Z",
          "start_time": "2020-06-23T22:25:54.505221Z"
        },
        "colab_type": "code",
        "id": "DV6YLt0oiicW",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        text = batch.text\n",
        "        tags = batch.nertags\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        predictions = model(text)\n",
        "\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "        #tags = [sent len, batch size]\n",
        "\n",
        "        # Reordenamos los datos para calcular la loss\n",
        "        predictions = predictions.view(-1, predictions.shape[-1])\n",
        "        tags = tags.view(-1)\n",
        "\n",
        "        #predictions = [sent len * batch size, output dim]\n",
        "        #tags = [sent len * batch size]\n",
        "\n",
        "        loss = criterion(predictions, tags)\n",
        "        precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_precision += precision\n",
        "        epoch_recall += recall\n",
        "        epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(\n",
        "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text = batch.text\n",
        "            tags = batch.nertags\n",
        "\n",
        "            predictions = model(text)\n",
        "\n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = tags.view(-1)\n",
        "\n",
        "            loss = criterion(predictions, tags)\n",
        "            precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_precision += precision\n",
        "            epoch_recall += recall\n",
        "            epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(\n",
        "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T21:49:02.524817Z",
          "start_time": "2020-06-23T21:47:09.863026Z"
        },
        "colab_type": "code",
        "id": "iK5lQqpviicf",
        "colab": {}
      },
      "source": [
        "def run_training(model, train_iterator, valid_iterator, optimizer, criterion, \n",
        "                 n_epochs, patience=2):\n",
        "  best_valid_loss = float('inf')\n",
        "  prev_loss = float('inf')\n",
        "\n",
        "  # Enviamos el modelo y la loss a cuda (en el caso en que esté disponible)\n",
        "  model = model.to(device)\n",
        "  criterion = criterion.to(device)\n",
        "\n",
        "  counter = 0\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "      start_time = time.time()\n",
        "      \n",
        "      train_loss, train_precision, train_recall, train_f1 = train(\n",
        "          model, train_iterator, optimizer, criterion)\n",
        "\n",
        "      valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "          model, valid_iterator, criterion)\n",
        "\n",
        "      end_time = time.time()\n",
        "\n",
        "      epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "      # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n",
        "      # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de código.\n",
        "      if valid_loss < best_valid_loss:\n",
        "          best_valid_loss = valid_loss\n",
        "          torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
        "      # Si ya no mejoramos el loss de validación, terminamos de entrenar.\n",
        "\n",
        "      print(f'Epoch: {epoch+1:02}/{n_epochs} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "      print(\n",
        "          f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "      )\n",
        "      print(\n",
        "          f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "      )\n",
        "\n",
        "      # Early stopping\n",
        "      if valid_loss >= prev_loss:\n",
        "        counter += 1\n",
        "      \n",
        "      if counter == patience:\n",
        "        break\n",
        "\n",
        "      prev_loss = valid_loss\n",
        "  \n",
        "  \n",
        "  # cargar el mejor modelo entrenado.\n",
        "  model.load_state_dict(torch.load('{}.pt'.format(model_name)))\n",
        "\n",
        "  # Evaluamos el set de validación con el modelo final\n",
        "  valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "      model, valid_iterator, criterion)\n",
        "  print('------------------------------------------------')\n",
        "  print('---------------- BEST MODEL --------------------')\n",
        "  print('------------------------------------------------')\n",
        "  print(\n",
        "      f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "  )\n",
        "  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.654826Z",
          "start_time": "2020-06-23T22:25:51.103450Z"
        },
        "colab_type": "code",
        "id": "9mUOOLEWiicU",
        "colab": {}
      },
      "source": [
        "# Definimos las métricas\n",
        "\n",
        "# Noten que la evaluación solo se hace para las Named Entities (sin contar 'O').\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import warnings\n",
        "import sklearn.exceptions\n",
        "warnings.filterwarnings(\"ignore\",\n",
        "                        category=sklearn.exceptions.UndefinedMetricWarning)\n",
        "\n",
        "\n",
        "def calculate_metrics(preds, y_true, pad_idx=PAD_TAG_IDX, o_idx=O_TAG_IDX):\n",
        "    \"\"\"\n",
        "    Calcula precision, recall y f1 de cada batch.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtener el indice de la clase con probabilidad mayor. (clases)\n",
        "    y_pred = preds.argmax(dim=1, keepdim=True)\n",
        "    # Obtenemos los indices distintos de 0.\n",
        "\n",
        "    # filtramos <pad> y O para calcular los scores.\n",
        "    mask = [(y_true != o_idx) & (y_true != pad_idx)]\n",
        "    y_pred = y_pred[mask]\n",
        "    y_true = y_true[mask]\n",
        "\n",
        "    # traemos a la cpu\n",
        "    y_pred = y_pred.view(-1).to('cpu')\n",
        "    y_true = y_true.to('cpu')\n",
        "    \n",
        "    # calcular scores\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    return precision, recall, f1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hod516H1aSG2"
      },
      "source": [
        "-------------------\n",
        "\n",
        "### Modelo Baseline\n",
        "\n",
        "Teniendo ya cargado los datos, toca definir nuestro modelo. Este baseline tendrá una capa de embedding, unas cuantas LSTM y una capa de salida y usará dropout en el entrenamiento.\n",
        "\n",
        "Este constará de los siguientes pasos: \n",
        "\n",
        "1. Definir la clase que contendrá la red.\n",
        "2. Definir los hiperparámetros e inicializar la red. \n",
        "3. Definir la época de entrenamiento\n",
        "3. Definir la función de loss.\n",
        "\n",
        "\n",
        "\n",
        "Recomendamos que para experimentar, encapsules los modelos en una sola variable y luego la fijes en model para entrenarla"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.666751Z",
          "start_time": "2020-06-23T22:25:51.656778Z"
        },
        "colab_type": "code",
        "id": "rMPL08XqaSG3",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class NER_RNN(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim,\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=pad_idx)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T21:43:02.333880Z",
          "start_time": "2020-06-22T21:43:02.329861Z"
        },
        "colab_type": "text",
        "id": "cCl3530VaSG7"
      },
      "source": [
        "#### Hiperparámetros de la red\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdr8OzmVg-Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "    # Inicializamos los pesos como aleatorios\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean=0, std=0.1) \n",
        "        \n",
        "    # Seteamos como 0 los embeddings de UNK y PAD.\n",
        "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.705684Z",
          "start_time": "2020-06-23T22:25:51.668746Z"
        },
        "colab_type": "code",
        "id": "EHdi3QdOaSG8",
        "colab": {}
      },
      "source": [
        "# tamaño del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100  # dimensión de los embeddings.\n",
        "HIDDEN_DIM = 128  # dimensión de la capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)  # número de clases\n",
        "\n",
        "N_LAYERS = 2  # número de capas.\n",
        "DROPOUT = 0.25\n",
        "BIDIRECTIONAL = False\n",
        "\n",
        "# Creamos nuestro modelo.\n",
        "baseline_model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "baseline_model_name = 'baseline'  # nombre que tendrá el modelo guardado...\n",
        "baseline_n_epochs = 10\n",
        "\n",
        "# Loss: Cross Entropy\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "baseline_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.805380Z",
          "start_time": "2020-06-23T22:25:51.751524Z"
        },
        "colab_type": "code",
        "id": "Q-G_NWFcaSHe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "4b1bf805-b92f-4c1d-b128-10d69adbb021"
      },
      "source": [
        "model = baseline_model\n",
        "model_name = baseline_model_name\n",
        "criterion = baseline_criterion\n",
        "n_epochs = baseline_n_epochs\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NER_RNN(\n",
              "  (embedding): Embedding(26101, 100, padding_idx=1)\n",
              "  (lstm): LSTM(100, 128, num_layers=2, dropout=0.25)\n",
              "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UVqBqerlaSHk"
      },
      "source": [
        "Por último, definimos los embeddings que representan a \\<unk\\> y \\<pad\\>  como [0, 0, ..., 0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiKRbZ7-6Q8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "76ea018a-4a53-45e0-eb9e-6ec20b6de7c5"
      },
      "source": [
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs=10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.446 | Train f1: 0.11 | Train precision: 0.14 | Train recall: 0.12\n",
            "\t Val. Loss: 0.322 |  Val. f1: 0.26 |  Val. precision: 0.30 | Val. recall: 0.27\n",
            "Epoch: 02/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.184 | Train f1: 0.44 | Train precision: 0.49 | Train recall: 0.44\n",
            "\t Val. Loss: 0.235 |  Val. f1: 0.47 |  Val. precision: 0.56 | Val. recall: 0.46\n",
            "Epoch: 03/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.114 | Train f1: 0.62 | Train precision: 0.67 | Train recall: 0.63\n",
            "\t Val. Loss: 0.235 |  Val. f1: 0.52 |  Val. precision: 0.60 | Val. recall: 0.51\n",
            "Epoch: 04/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.078 | Train f1: 0.72 | Train precision: 0.75 | Train recall: 0.72\n",
            "\t Val. Loss: 0.228 |  Val. f1: 0.57 |  Val. precision: 0.64 | Val. recall: 0.58\n",
            "Epoch: 05/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.059 | Train f1: 0.78 | Train precision: 0.80 | Train recall: 0.78\n",
            "\t Val. Loss: 0.234 |  Val. f1: 0.57 |  Val. precision: 0.64 | Val. recall: 0.57\n",
            "Epoch: 06/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.046 | Train f1: 0.82 | Train precision: 0.84 | Train recall: 0.82\n",
            "\t Val. Loss: 0.246 |  Val. f1: 0.58 |  Val. precision: 0.64 | Val. recall: 0.58\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.228 |  Val. f1: 0.57 | Val. precision: 0.64 | Val. recall: 0.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9spX-Hkh8YJg"
      },
      "source": [
        "### Modelos\n",
        "\n",
        "*   **[DONE]** Probar Early stopping\n",
        "*   Variar la cantidad de parámetros de la capa de embeddings.\n",
        "*   **[DONE]** Variar la cantidad de capas RNN.\n",
        "*   Variar la cantidad de parámetros de las capas de RNN.\n",
        "*   Inicializar la capa de embeddings con modelos pre-entrenados. (word2vec, glove, conceptnet, etc...).[Guía breve aquí](https://github.com/dccuchile/spanish-word-embeddings), [Embeddings en español aquí](https://github.com/dccuchile/spanish-word-embeddings).\n",
        "*   **[DONE]** Variar la cantidad de épocas de entrenamiento.\n",
        "*   Variar el optimizador, learning rate, batch size, usar CRF loss, etc...\n",
        "*   **[DONE]** Probar bi-direccionalidad.\n",
        "*   Probar teacher forcing.\n",
        "*   **[DONE]** Incluir dropout.\n",
        "*   Probar modelos de tipo GRU\n",
        "*   Probar Embedding Contextuales (les puede ser de utilidad [flair](https://github.com/flairNLP/flair))\n",
        "*   Probar modelos de transformers en español usando [Huggingface](https://github.com/huggingface/transformers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lRYOEDiQaSHK"
      },
      "source": [
        "--------------------\n",
        "### Modelo 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.722604Z",
          "start_time": "2020-06-23T22:25:51.717615Z"
        },
        "colab_type": "code",
        "id": "c81f8ki5aSHL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "83da3616-bcf3-4cc4-9fea-091b75eb92d3"
      },
      "source": [
        "BIDIRECTIONAL = True\n",
        "model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX).apply(init_weights)\n",
        "\n",
        "model_name = 'bi_rnn'  # nombre que tendrá el modelo guardado\n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01/10 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.359 | Train f1: 0.25 | Train precision: 0.32 | Train recall: 0.24\n",
            "\t Val. Loss: 0.289 |  Val. f1: 0.43 |  Val. precision: 0.53 | Val. recall: 0.41\n",
            "Epoch: 02/10 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.125 | Train f1: 0.60 | Train precision: 0.66 | Train recall: 0.60\n",
            "\t Val. Loss: 0.270 |  Val. f1: 0.55 |  Val. precision: 0.65 | Val. recall: 0.53\n",
            "Epoch: 03/10 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.070 | Train f1: 0.74 | Train precision: 0.77 | Train recall: 0.74\n",
            "\t Val. Loss: 0.281 |  Val. f1: 0.56 |  Val. precision: 0.65 | Val. recall: 0.54\n",
            "Epoch: 04/10 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.043 | Train f1: 0.82 | Train precision: 0.84 | Train recall: 0.82\n",
            "\t Val. Loss: 0.292 |  Val. f1: 0.58 |  Val. precision: 0.67 | Val. recall: 0.55\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.270 |  Val. f1: 0.55 | Val. precision: 0.65 | Val. recall: 0.53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rV9oLkN1aSHO"
      },
      "source": [
        "---------------\n",
        "\n",
        "### Modelo 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaMtZ5lrseP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "e4dfa1fb-a003-44ec-8024-83841538f214"
      },
      "source": [
        "model = NER_RNN(input_dim=len(TEXT.vocab),\n",
        "                embedding_dim=100,\n",
        "                hidden_dim=200,\n",
        "                output_dim=len(NER_TAGS.vocab),\n",
        "                n_layers=3,\n",
        "                bidirectional=True,\n",
        "                dropout=0.2,\n",
        "                pad_idx=PAD_IDX).apply(init_weights)\n",
        "\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')\n",
        "\n",
        "model_name = 'bigger_bi_rnn'  # nombre que tendrá el modelo guardado\n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 5,023,710 parámetros entrenables.\n",
            "Epoch: 01/10 | Epoch Time: 0m 16s\n",
            "\tTrain Loss: 0.326 | Train f1: 0.27 | Train precision: 0.31 | Train recall: 0.28\n",
            "\t Val. Loss: 0.263 |  Val. f1: 0.41 |  Val. precision: 0.49 | Val. recall: 0.41\n",
            "Epoch: 02/10 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.126 | Train f1: 0.60 | Train precision: 0.65 | Train recall: 0.61\n",
            "\t Val. Loss: 0.220 |  Val. f1: 0.54 |  Val. precision: 0.61 | Val. recall: 0.55\n",
            "Epoch: 03/10 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.076 | Train f1: 0.74 | Train precision: 0.77 | Train recall: 0.75\n",
            "\t Val. Loss: 0.229 |  Val. f1: 0.57 |  Val. precision: 0.63 | Val. recall: 0.58\n",
            "Epoch: 04/10 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.056 | Train f1: 0.81 | Train precision: 0.83 | Train recall: 0.81\n",
            "\t Val. Loss: 0.234 |  Val. f1: 0.59 |  Val. precision: 0.66 | Val. recall: 0.59\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.220 |  Val. f1: 0.54 | Val. precision: 0.61 | Val. recall: 0.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRuPM9QlyxG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "8fce1f2f-736c-43c5-851e-dc640a3f51a1"
      },
      "source": [
        "# glove pretrained embeddings\n",
        "!wget http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-22 03:29:21--  http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz\n",
            "Resolving dcc.uchile.cl (dcc.uchile.cl)... 192.80.24.11\n",
            "Connecting to dcc.uchile.cl (dcc.uchile.cl)|192.80.24.11|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz [following]\n",
            "--2020-07-22 03:29:21--  https://www.dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz\n",
            "Resolving www.dcc.uchile.cl (www.dcc.uchile.cl)... 200.9.99.213, 192.80.24.11\n",
            "Connecting to www.dcc.uchile.cl (www.dcc.uchile.cl)|200.9.99.213|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://users.dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz [following]\n",
            "--2020-07-22 03:29:22--  https://users.dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz\n",
            "Resolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 200.9.99.211, 192.80.24.4\n",
            "Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|200.9.99.211|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 949886421 (906M) [application/x-gzip]\n",
            "Saving to: ‘glove-sbwc.i25.vec.gz’\n",
            "\n",
            "glove-sbwc.i25.vec. 100%[===================>] 905.88M  6.95MB/s    in 2m 12s  \n",
            "\n",
            "2020-07-22 03:31:35 (6.84 MB/s) - ‘glove-sbwc.i25.vec.gz’ saved [949886421/949886421]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T16:07:45.755561Z",
          "start_time": "2020-06-22T16:07:45.751571Z"
        },
        "colab_type": "text",
        "id": "Zpy3p7YaaSHT"
      },
      "source": [
        "---------------\n",
        "\n",
        "\n",
        "### Modelo 3: Mayor batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2oCe4DrvkhT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90803dc2-e891-420f-a301-3ecad80164bf"
      },
      "source": [
        "BATCH_SIZE = 64  # disminuir si hay problemas de ram.\n",
        "\n",
        "# Usar cuda si es que está disponible.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "# Dividir datos entre entrenamiento y test\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort=False,\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.728587Z",
          "start_time": "2020-06-23T22:25:51.724596Z"
        },
        "colab_type": "code",
        "id": "KWPzETaNaSHP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "f466cf5c-7813-4739-e8dd-fa6b2fb1dd88"
      },
      "source": [
        "model = NER_RNN(input_dim=len(TEXT.vocab),\n",
        "                embedding_dim=100,\n",
        "                hidden_dim=200,\n",
        "                output_dim=len(NER_TAGS.vocab),\n",
        "                n_layers=3,\n",
        "                bidirectional=True,\n",
        "                dropout=0.3,\n",
        "                pad_idx=PAD_IDX).apply(init_weights)\n",
        "\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')\n",
        "\n",
        "model_name = 'bigger_bi_rnn'  # nombre que tendrá el modelo guardado\n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 5,023,710 parámetros entrenables.\n",
            "Epoch: 01/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.615 | Train f1: 0.01 | Train precision: 0.02 | Train recall: 0.01\n",
            "\t Val. Loss: 0.420 |  Val. f1: 0.04 |  Val. precision: 0.06 | Val. recall: 0.08\n",
            "Epoch: 02/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.250 | Train f1: 0.20 | Train precision: 0.23 | Train recall: 0.23\n",
            "\t Val. Loss: 0.314 |  Val. f1: 0.25 |  Val. precision: 0.30 | Val. recall: 0.26\n",
            "Epoch: 03/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.197 | Train f1: 0.32 | Train precision: 0.38 | Train recall: 0.35\n",
            "\t Val. Loss: 0.318 |  Val. f1: 0.35 |  Val. precision: 0.47 | Val. recall: 0.35\n",
            "Epoch: 04/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.135 | Train f1: 0.52 | Train precision: 0.58 | Train recall: 0.53\n",
            "\t Val. Loss: 0.279 |  Val. f1: 0.52 |  Val. precision: 0.57 | Val. recall: 0.54\n",
            "Epoch: 05/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.093 | Train f1: 0.67 | Train precision: 0.70 | Train recall: 0.67\n",
            "\t Val. Loss: 0.273 |  Val. f1: 0.53 |  Val. precision: 0.60 | Val. recall: 0.54\n",
            "Epoch: 06/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.070 | Train f1: 0.74 | Train precision: 0.76 | Train recall: 0.74\n",
            "\t Val. Loss: 0.295 |  Val. f1: 0.55 |  Val. precision: 0.61 | Val. recall: 0.57\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.273 |  Val. f1: 0.53 | Val. precision: 0.60 | Val. recall: 0.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN5Xuo9YwjOl",
        "colab_type": "text"
      },
      "source": [
        "---------------\n",
        "\n",
        "\n",
        "### Modelo 4: Agregar más capas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N7rqPJPtkPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NER_RNN2(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim,\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=pad_idx)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Sequential(nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                                          hidden_dim),\n",
        "                                nn.BatchNorm1d(num_features=hidden_dim),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.733572Z",
          "start_time": "2020-06-23T22:25:51.730580Z"
        },
        "colab_type": "code",
        "id": "_w0CFjA8aSHU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "021b8e7f-4098-4347-c292-26024bb049bd"
      },
      "source": [
        "model = NER_RNN2(input_dim=len(TEXT.vocab),\n",
        "                embedding_dim=100,\n",
        "                hidden_dim=200,\n",
        "                output_dim=len(NER_TAGS.vocab),\n",
        "                n_layers=3,\n",
        "                bidirectional=True,\n",
        "                dropout=0.3,\n",
        "                pad_idx=PAD_IDX).apply(init_weights)\n",
        "\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')\n",
        "\n",
        "model_name = 'bigger_bi_rnn'  # nombre que tendrá el modelo guardado\n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 5,102,310 parámetros entrenables.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f64c1a17c57f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-081d8827a530>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs, patience)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       train_loss, train_precision, train_recall, train_f1 = train(\n\u001b[0;32m---> 16\u001b[0;31m           model, train_iterator, optimizer, criterion)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
            "\u001b[0;32m<ipython-input-11-73013c51e640>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#text = [sent len, batch size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#predictions = [sent len, batch size, output dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-4a6fb45b3115>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;31m#predictions = [sent len, batch size, output dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1921\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1922\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m     )\n\u001b[1;32m   1925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 64 elements not 200"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T21:52:04.077979Z",
          "start_time": "2020-06-23T21:52:04.072991Z"
        },
        "id": "9NNSdjcCzXzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Limpiar ram de cuda\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uF1ysw_Kw6zz"
      },
      "source": [
        "\n",
        "## Predecir datos para la competencia\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:31:56.776563Z",
          "start_time": "2020-06-23T22:31:39.654525Z"
        },
        "colab_type": "code",
        "id": "1RBs3UU4wLk3",
        "colab": {}
      },
      "source": [
        "def predict_labels(model, iterator, criterion, fields=fields):\n",
        "\n",
        "    # Extraemos los vocabularios.\n",
        "    text_field = fields[0][1]\n",
        "    nertags_field = fields[1][1]\n",
        "    tags_vocab = nertags_field.vocab.itos\n",
        "    words_vocab = text_field.vocab.itos\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            text_batch = batch.text\n",
        "            text_batch = torch.transpose(text_batch, 0, 1).tolist()\n",
        "\n",
        "            # Predecir los tags de las sentences del batch\n",
        "            predictions_batch = model(batch.text)\n",
        "            predictions_batch = torch.transpose(predictions_batch, 0, 1)\n",
        "\n",
        "            # por cada oración predicha:\n",
        "            for sentence, sentence_prediction in zip(text_batch,\n",
        "                                                     predictions_batch):\n",
        "                for word_idx, word_predictions in zip(sentence,\n",
        "                                                      sentence_prediction):\n",
        "                    # Obtener el indice del tag con la probabilidad mas alta.\n",
        "                    argmax_index = word_predictions.topk(1)[1]\n",
        "\n",
        "                    current_tag = tags_vocab[argmax_index]\n",
        "                    # Obtenemos la palabra\n",
        "                    current_word = words_vocab[word_idx]\n",
        "\n",
        "                    if current_word != '<pad>':\n",
        "                        predictions.append([current_word, current_tag])\n",
        "\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "predictions = predict_labels(model, test_iterator, criterion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YwQp1Ru8Oht8"
      },
      "source": [
        "### Generar el archivo para la submission\n",
        "\n",
        "No hay problema si aparecen unk en la salida. Estos no son relevantes para evaluarlos, usamos solo los tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:33:41.845955Z",
          "start_time": "2020-06-23T22:33:41.731717Z"
        },
        "colab_type": "code",
        "id": "RPfZkjJGkWyq",
        "colab": {}
      },
      "source": [
        "import os, shutil\n",
        "\n",
        "if (os.path.isfile('./predictions.zip')):\n",
        "    os.remove('./predictions.zip')\n",
        "\n",
        "if (not os.path.isdir('./predictions')):\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "else:\n",
        "    # Eliminar predicciones anteriores:\n",
        "    shutil.rmtree('./predictions')\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "f = open('predictions/predictions.txt', 'w')\n",
        "for word, tag in predictions:\n",
        "    f.write(word + ' ' + tag + '\\n')\n",
        "f.write('\\n')\n",
        "f.close()\n",
        "\n",
        "a = shutil.make_archive('predictions', 'zip', './predictions')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T21:49:19.575711Z",
          "start_time": "2020-06-23T21:49:19.100486Z"
        },
        "colab_type": "code",
        "id": "k2PqvJAmTFWR",
        "colab": {}
      },
      "source": [
        "# A veces no funciona a la primera. Ejecutar mas de una vez para obtener el archivo...\n",
        "from google.colab import files\n",
        "files.download('predictions.zip')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LZEWJXrNaSIf"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "\n",
        "\n",
        "..."
      ]
    }
  ]
}