{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Tarea_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z0tyIsliieNr"
      },
      "source": [
        "# Tarea 2 - Named Entity Recognition\n",
        "\n",
        "----------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T15:21:15.416464Z",
          "start_time": "2020-06-22T15:21:15.411478Z"
        },
        "colab_type": "text",
        "id": "X3QUWWoWaSE3"
      },
      "source": [
        "- **Nombre:** Martín Valderrama, Jou-Hui Ho\n",
        "\n",
        "- **Usuario o nombre de equipo en Codalab:** pibjou\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W_dxGEs3iiau"
      },
      "source": [
        "\n",
        "## Introducción a la tarea\n",
        "\n",
        "### Objetivo\n",
        "\n",
        "\n",
        "El objetivo de esta tarea es resolver una de las tasks mas importantes de Sequence Labelling: [Named Entity Recognition (NER)](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf). \n",
        "\n",
        "\n",
        "Esperamos que (por lo menos) utilizen Redes Neuronales Recurrentes (RNN) para resolverla. Nuevamente, hay total libertad para utilizar software y los modelos que deseen, siempre y cuando estos no traigan los modelos ya implementados (como el caso de spacy).\n",
        "\n",
        "\n",
        "**Named Entity Recognition (NER)**\n",
        "\n",
        "Esta tarea consiste en localizar y clasificar los tokens de una oración que representen entidades nombradas. Es decir, tokens que simbolicen (1) **personas**, (2) **organizaciones**, (3) **lugares** y (4) **adjetivos, eventos y otras entidades que no entren en las categorías anteriores** deberán ser taggeados como (1) **PER**, (2) **ORG**, (3) **LOC** y (4) **MISC** respectivamente. Adicionalmente, dado que existen entidades representadas en más de un token (como La Serena), se utiliza la notación BIO como prefijo al tag: Beginning, Inside, Outside. Es decir, si encuentro una entidad, el primer token etiquetado será precedido por B, el segundo por I y los n restantes por I. Por otra parte, si el token no representa ninguna entidad nombrada, se representa por O. Un ejemplo de esto es:\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "```\n",
        "Felipe B-PER\n",
        "Bravo I-PER\n",
        "es O\n",
        "el O\n",
        "profesor O\n",
        "de O\n",
        "PLN B-MISC\n",
        "de O\n",
        "la O\n",
        "Universidad B-ORG\n",
        "de I-ORG\n",
        "Chile I-ORG\n",
        ". O\n",
        "```\n",
        "\n",
        "Estos links son los más indicados para comenzar:\n",
        "\n",
        "-  [Tagging, and Hidden Markov Models ](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf) (slides by Michael Collins), [notes](http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf), [video 1](https://youtu.be/-ngfOZz8yK0), [video 2](https://youtu.be/PLoLKQwkONw), [video 3](https://youtu.be/aaa5Qoi8Vco), [video 4](https://youtu.be/4pKWIDkF_6Y)       \n",
        "-  [Recurrent Neural Networks](slides/NLP-RNN.pdf) | [video 1](https://youtu.be/BmhjUkzz3nk), [video 2](https://youtu.be/z43YFR1iIvk), [video 3](https://youtu.be/7L5JxQdwNJk)\n",
        "\n",
        "\n",
        "Recuerden que todo el material se encuentra disponible en el [github del curso](https://github.com/dccuchile/CC6205)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V5BBxJWQaSE-"
      },
      "source": [
        "**Link a la competencia:  https://competitions.codalab.org/competitions/25302?secret_key=690406c7-b3b0-4092-8694-d08d7991ca94**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4HfZqQ-_aSFE"
      },
      "source": [
        "### Reporte\n",
        "\n",
        "Este debe cumplir la siguiente estructura:\n",
        "\n",
        "1.\t**Introducción**: Presentar brevemente el problema a resolver, los modelos utilizados en el desarrollo de la tarea y conclusiones obtenidas. (0.5 Puntos)\n",
        "\n",
        "2.\t**Modelos**: Describir brevemente los modelos, métodos y hiperparámetros utilizados. (1.0 puntos)\n",
        "\n",
        "4.\t**Métricas de evaluación**: Describir las métricas utilizadas en la evaluación indicando que miden y cuál es su interpretación en este problema en particular. (0.5 puntos)\n",
        "\n",
        "5.\t**Experimentos**: Reportar todos sus experimentos y código en esta sección. Comparar los resultados obtenidos utilizando diferentes modelos. ¡Es vital haber realizado varios experimentos para sacar una buena nota! (3.0 puntos)\n",
        "\n",
        "6.\t**Conclusiones**: Discutir resultados, proponer trabajo futuro. (1.0 punto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f7X2FruyaSFG"
      },
      "source": [
        "\n",
        "-----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PzQlYlmGaSFH"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "\n",
        "El objetivo de este trabajo es resolver el problema de Named Entity Recognition (NER), que corresponde a una task de Sequence Labelling. Consiste en localizar y clasificar los tokes de una oración que representen alguna de las siguientes entidades: (1) **personas (PER)**, (2) **organizaciones (ORG)**, (3) **lugares (LOC)** y (4) **adjetivos, eventos y otras entidades que no entren en las categorías anteriores (MISC)**.\n",
        "\n",
        "Para ello, se utiliza el dataset en español entregado por el cuerpo docente, cuyos datos contienen etiquetas de las entidades correspondientes, y también si la palabra es el comienzo del nombre de una entidad, está al medio, o es el término, mediante la notación BIO: Beginning, Inside, Outside.\n",
        "\n",
        "Se prueban distintos modelos para resolver este problema, tales como redes neuronales recurrentes (RNN), LSTM, GRU, variando además los hiperparámetros asociados a cada modelo y los pesos de las capas. El desempeño de cada modelo es medido a través de los valores de precision, recall y F1 score que entregan.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UbA1EmhCaSFI"
      },
      "source": [
        "## Modelos \n",
        "\n",
        "Los modelos a utilizar, se basan altamente en el baseline. Con él, se implementa una capa recurrente (LSTM o GRU), a la que se le alimenta con una capa de emmbeding, la cual, en los experimentos, se ve creada con pesos pre-entrenados.\n",
        "\n",
        "Capas:\n",
        "\n",
        "- Embedding: en esta capa se transforman las palabras a vectores de características para posteriormente ser pasados por la red. Se pueden crear con modelos pre-entrenados para palabras en español.\n",
        "- LSTM: Es la capa que se encarga de extraer características contextuales de las palabras. Como se aplica una arquitectura bidireccional, la red obtiene información de las palabras anteriores, como de las palabras posteriores a la que se está clasificando.\n",
        "- GRU: Lo mismo que pasa en la capa LSTM, pasa en esta capa, de hecho, los parámetros que se le entregan son los mismos. Ahora, la capa GRU es una simplificación de la LSTM, donde se reduce el proceso de compuertas.\n",
        "- Dropout: Se agrega Dropout para evitar overfitt de la capa _fully connected_ respecto a las capas recurrentes anteriores.\n",
        "- Fully Connected: Esta capa se encarga de tomar las características entregadas por la capa recurrente anterior, y se clasifica entre los tags disponibles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AaVhZ5iaaSFK"
      },
      "source": [
        "## Métricas de evaluación\n",
        "\n",
        "Para evaluar el desempeño de los distintos modelos, se utilizan las siguientes métricas sobre todas las clases menos la clase 'O', ya que es la clase 'negativa', es decir, que la etiqueta corresponde a que no hay ninguna identidad en la palabra. Puede ser relevante incluirla también, pero como es la clase mayoritaria (la mayoría de las palabras no son entidades), podría entregar un resultado no representativo dado el desbalance entre clases.\n",
        "\n",
        "- **Precision:** TP/(TP+FP)\n",
        "\n",
        "  Es la razón entre los datos positivos correctamente predichos y el total de datos que fueron predichos como positivos. Intuitivamente, esta métrica responde a la pregunta: ¿dentro de todos los datos clasificados como positivos, cuántos realmente eran positivos? En el problema de NER, correspondería a la tasa de palabras que eran realmente una entidad X dentro de todas las palabras clasificadas como dicha entidad.\n",
        "\n",
        "\n",
        "- **Recall:** TP/(TP+FN)\n",
        "\n",
        "  Es la razón entre los datos positivos correctamente predichos y el total de los datos positivos reales. Responde a la pregunta: Dentro de los datos que eran realmente positivos, ¿cuántos recuperé? En NER, equivale a la tasa de palabras correctamente clasificadas como una entidad X dentro de todas las palabras que realmente eran de esa entidad.\n",
        "\n",
        "\n",
        "- **F1 score:** 2*(Recall * Precision) / (Recall + Precision)\n",
        "\n",
        "  Es el promedio ponderado entre precision y recall, por lo que considera tanto falsos positivos como falsos negativos. Para obtener un alto F1 score, es necesario tener alta precision y recall. Esta métrica es útil cuando existen clases muy desbalanceadas, donde falsos positivos (o negativos) tienen distinta importancia, como es el caso de este problema, donde tenemos una distribución dispar entre las distintas clases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T15:44:52.175773Z",
          "start_time": "2020-06-22T15:44:52.172782Z"
        },
        "colab_type": "text",
        "id": "uFM-wNt8aSFM"
      },
      "source": [
        "## Experimentos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R6Nhas6yGZ7",
        "colab_type": "text"
      },
      "source": [
        "Los experimentos que se realizan son:\n",
        "\n",
        "- Variación de hiper parámetros como: tamaño del batch, paso de aprendizaje, cantidad de capas, tasa de dropout.\n",
        "- Variación en embeddings que se utilizan. Para este ejercicio se utilizan dos embeddings pre-entrenados: GloVe y FastText obtenidos del repositorio del DCC.\n",
        "- Se cambia la capa LSTM por una GRU para evaluar el mejor rendimiento entre ellas. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LMgKjfYC_Go-"
      },
      "source": [
        "###  Carga de datos y Preprocesamiento\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:24:52.392908Z",
          "start_time": "2020-06-23T22:24:50.641641Z"
        },
        "colab_type": "code",
        "id": "27csY87GaSFO",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "0f5421a3-8efe-42bc-8cf8-d7681790d7f0"
      },
      "source": [
        "# Instalar torchtext (en codalab) - Descomentar.\n",
        "!pip3 install torchtext==0.6"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.6 in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (1.6.0+cu101)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (0.1.91)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6) (2020.6.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:24:53.086354Z",
          "start_time": "2020-06-23T22:24:52.394902Z"
        },
        "colab_type": "code",
        "id": "ng7wRGEyawjM",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data, datasets\n",
        "\n",
        "# Garantizar reproducibilidad \n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:49.789218Z",
          "start_time": "2020-06-23T22:24:53.088871Z"
        },
        "colab_type": "code",
        "id": "lbT0g_kC18Jb",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/Data/train_NER_esp.txt -nc # Dataset de Entrenamiento\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/Data/val_NER_esp.txt -nc    # Dataset de Validación (Para probar y ajustar el modelo)\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/Data/test_NER_esp.txt -nc  # Dataset de la Competencia. Estos datos solo contienen los tokens. ¡¡SON LOS QUE DEBEN SER PREDICHOS!!"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uMud7YGMBZvg"
      },
      "source": [
        "####  Fields\n",
        "\n",
        "Un `field`:\n",
        "\n",
        "* Define un tipo de datos junto con instrucciones para convertir el texto a Tensor.\n",
        "* Contiene un objeto `Vocab` que contiene el vocabulario (palabras posibles que puede tomar ese campo).\n",
        "* Contiene otros parámetros relacionados con la forma en que se debe numericalizar un tipo de datos, como un método de tokenización y el tipo de Tensor que se debe producir.\n",
        "\n",
        "\n",
        "Analizemos el siguiente cuadro el cual contiene un ejemplo cualquiera de entrenamiento:\n",
        "\n",
        "\n",
        "```\n",
        "El O\n",
        "Abogado B-PER\n",
        "General I-PER\n",
        "del I-PER\n",
        "Estado I-PER\n",
        ", O\n",
        "Daryl B-PER\n",
        "Williams I-PER\n",
        "```\n",
        "\n",
        "Cada linea contiene una palabra y su clase. Para que `torchtext` pueda cargar estos datos, debemos definir como va a leer y separar los componentes de cada una de las lineas.\n",
        "Para esto, definiremos un field para cada uno de esos componentes: Las palabras (`TEXT`) y los NER_TAGS (`clase`).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:49.795126Z",
          "start_time": "2020-06-23T22:25:49.791108Z"
        },
        "colab_type": "code",
        "id": "3DcM_IjgCdzz",
        "colab": {}
      },
      "source": [
        "# Primer Field: TEXT. Representan los tokens de la secuencia\n",
        "TEXT = data.Field(lower=False) \n",
        "\n",
        "# Segundo Field: NER_TAGS. Representan los Tags asociados a cada palabra.\n",
        "NER_TAGS = data.Field(unk_token=None)\n",
        "\n",
        "fields = ((\"text\", TEXT), (\"nertags\", NER_TAGS))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xCKTJOdgC5eC"
      },
      "source": [
        "####  SequenceTaggingDataset\n",
        "\n",
        "`SequenceTaggingDataset` es una clase de torchtext diseñada para contener datasets de sequence labelling. \n",
        "Los ejemplos que se guarden en una instancia de estos serán arreglos de palabras pareados con sus respectivos tags.\n",
        "Por ejemplo, para Part-of-speech tagging:\n",
        "\n",
        "[I, love, PyTorch, .] estará pareado con [PRON, VERB, PROPN, PUNCT]\n",
        "\n",
        "\n",
        "La idea es que usando los fields que definimos antes, le indiquemos a la clase cómo cargar los datasets de prueba, validación y test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.294370Z",
          "start_time": "2020-06-23T22:25:49.797092Z"
        },
        "colab_type": "code",
        "id": "HsHdGml62J21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b7254b5a-6c15-4858-d5ee-1f49279e0106"
      },
      "source": [
        "train_data, valid_data, test_data = datasets.SequenceTaggingDataset.splits(\n",
        "    path=\"./\",\n",
        "    train=\"train_NER_esp.txt\",\n",
        "    validation=\"val_NER_esp.txt\",\n",
        "    test=\"test_NER_esp.txt\",\n",
        "    fields=fields,\n",
        "    encoding=\"iso-8859-1\",\n",
        "    separator=\" \"\n",
        ")\n",
        "\n",
        "print(f\"Numero de ejemplos de entrenamiento: {len(train_data)}\")\n",
        "print(f\"Número de ejemplos de validación: {len(valid_data)}\")\n",
        "print(f\"Número de ejemplos de test (competencia): {len(test_data)}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de ejemplos de entrenamiento: 8323\n",
            "Número de ejemplos de validación: 1915\n",
            "Número de ejemplos de test (competencia): 1517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.317313Z",
          "start_time": "2020-06-23T22:25:50.303361Z"
        },
        "colab_type": "code",
        "id": "T023Ld4RaSF4",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "17ae8346-4fa6-45b8-dd4b-bd71f3d00cbc"
      },
      "source": [
        "# # Un ejemplo\n",
        "import random\n",
        "random_item_idx = random.randint(0, len(train_data))\n",
        "random_example = train_data.examples[random_item_idx]\n",
        "list(zip(random_example.text, random_example.nertags))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Temperaturas', 'O'),\n",
              " ('en', 'O'),\n",
              " ('ascenso', 'O'),\n",
              " ('ligero', 'O'),\n",
              " ('en', 'O'),\n",
              " ('el', 'O'),\n",
              " ('área', 'O'),\n",
              " ('del', 'O'),\n",
              " ('cantábrico', 'O'),\n",
              " ('oriental', 'O'),\n",
              " (',', 'O'),\n",
              " ('La', 'B-LOC'),\n",
              " ('Rioja', 'I-LOC'),\n",
              " (',', 'O'),\n",
              " ('Navarra', 'B-LOC'),\n",
              " (',', 'O'),\n",
              " ('Aragón', 'B-LOC'),\n",
              " ('y', 'O'),\n",
              " ('en', 'O'),\n",
              " ('Canarias', 'B-LOC'),\n",
              " ('y', 'O'),\n",
              " ('sin', 'O'),\n",
              " ('cambios', 'O'),\n",
              " ('en', 'O'),\n",
              " ('el', 'O'),\n",
              " ('resto', 'O'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2l05KYy5FSUy"
      },
      "source": [
        "#### Construir los vocabularios para el texto y las etiquetas\n",
        "\n",
        "Los vocabularios son los obbjetos que contienen todos los tokens (de entrenamiento) posibles para ambos fields.\n",
        "El siguiente paso consiste en construirlos. Para esto, hacemos uso del método `Field.build_vocab` sobre cada uno de nuestros `fields`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.445968Z",
          "start_time": "2020-06-23T22:25:50.320305Z"
        },
        "colab_type": "code",
        "id": "PBhp7WICiibL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "8a9979ee-fba6-42bc-b0c7-f4a8c3f940e6"
      },
      "source": [
        "TEXT.build_vocab(train_data)\n",
        "NER_TAGS.build_vocab(train_data)\n",
        "\n",
        "print(f\"Tokens únicos en TEXT: {len(TEXT.vocab)}\")\n",
        "print(f\"Tokens únicos en NER_TAGS: {len(NER_TAGS.vocab)}\")\n",
        "\n",
        "#Veamos las posibles etiquetas que hemos cargado:\n",
        "print(NER_TAGS.vocab.itos)\n",
        "\n",
        "# Tokens mas frecuentes\n",
        "TEXT.vocab.freqs.most_common(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokens únicos en TEXT: 26101\n",
            "Tokens únicos en NER_TAGS: 10\n",
            "['<pad>', 'O', 'B-ORG', 'I-ORG', 'B-LOC', 'B-PER', 'I-PER', 'I-MISC', 'B-MISC', 'I-LOC']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('de', 17657),\n",
              " (',', 14716),\n",
              " ('la', 9571),\n",
              " ('que', 7516),\n",
              " ('.', 7263),\n",
              " ('el', 6905),\n",
              " ('en', 6484),\n",
              " ('\"', 5691),\n",
              " ('y', 5336),\n",
              " ('a', 4304)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.479897Z",
          "start_time": "2020-06-23T22:25:50.475889Z"
        },
        "id": "3T6zXWK8zXxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seteamos algunas variables que nos serán de utilidad mas adelante...\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "PAD_TAG_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "O_TAG_IDX = NER_TAGS.vocab.stoi['O']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.490885Z",
          "start_time": "2020-06-23T22:25:50.481873Z"
        },
        "colab_type": "code",
        "id": "tuXOsbJUiibh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "a108f071-55f6-47bf-8ca7-c73825c6ae62"
      },
      "source": [
        "# Frecuencia de los Tags\n",
        "\n",
        "def tag_percentage(tag_counts):\n",
        "    \n",
        "    total_count = sum([count for tag, count in tag_counts])\n",
        "    tag_counts_percentages = [(tag, count, count/total_count) for tag, count in tag_counts]\n",
        "  \n",
        "    return tag_counts_percentages\n",
        "\n",
        "print(\"Tag Ocurrencia Porcentaje\\n\")\n",
        "\n",
        "for tag, count, percent in tag_percentage(NER_TAGS.vocab.freqs.most_common()):\n",
        "    print(f\"{tag}\\t{count}\\t{percent*100:4.1f}%\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tag Ocurrencia Porcentaje\n",
            "\n",
            "O\t231920\t87.6%\n",
            "B-ORG\t7390\t 2.8%\n",
            "I-ORG\t4992\t 1.9%\n",
            "B-LOC\t4913\t 1.9%\n",
            "B-PER\t4321\t 1.6%\n",
            "I-PER\t3903\t 1.5%\n",
            "I-MISC\t3212\t 1.2%\n",
            "B-MISC\t2173\t 0.8%\n",
            "I-LOC\t1891\t 0.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T21:44:17.730460Z",
          "start_time": "2020-06-22T21:44:17.724482Z"
        },
        "colab_type": "text",
        "id": "y4wPiydnaSGs"
      },
      "source": [
        "#### Configuramos pytorch y dividimos los datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.101455Z",
          "start_time": "2020-06-23T22:25:50.492843Z"
        },
        "colab_type": "code",
        "id": "uB7cwLWpaSGs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "00b2923b-ff7a-40d0-ea78-98b8bb0350c4"
      },
      "source": [
        "BATCH_SIZE = 16  # disminuir si hay problemas de ram.\n",
        "\n",
        "# Usar cuda si es que está disponible.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "# Dividir datos entre entrenamiento y test\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort=False,\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ISH58OP2Efn",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:54.515194Z",
          "start_time": "2020-06-23T22:25:54.505221Z"
        },
        "colab_type": "code",
        "id": "DV6YLt0oiicW",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        text = batch.text\n",
        "        tags = batch.nertags\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        predictions = model(text)\n",
        "\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "        #tags = [sent len, batch size]\n",
        "\n",
        "        # Reordenamos los datos para calcular la loss\n",
        "        predictions = predictions.view(-1, predictions.shape[-1])\n",
        "        tags = tags.view(-1)\n",
        "\n",
        "        #predictions = [sent len * batch size, output dim]\n",
        "        #tags = [sent len * batch size]\n",
        "\n",
        "        loss = criterion(predictions, tags)\n",
        "        precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_precision += precision\n",
        "        epoch_recall += recall\n",
        "        epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(\n",
        "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text = batch.text\n",
        "            tags = batch.nertags\n",
        "\n",
        "            predictions = model(text)\n",
        "\n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = tags.view(-1)\n",
        "\n",
        "            loss = criterion(predictions, tags)\n",
        "            precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_precision += precision\n",
        "            epoch_recall += recall\n",
        "            epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(\n",
        "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T21:49:02.524817Z",
          "start_time": "2020-06-23T21:47:09.863026Z"
        },
        "colab_type": "code",
        "id": "iK5lQqpviicf",
        "colab": {}
      },
      "source": [
        "def run_training(model, train_iterator, valid_iterator, optimizer, criterion, \n",
        "                 n_epochs, patience=2):\n",
        "  best_valid_loss = float('inf')\n",
        "  prev_loss = float('inf')\n",
        "\n",
        "  # Enviamos el modelo y la loss a cuda (en el caso en que esté disponible)\n",
        "  model = model.to(device)\n",
        "  criterion = criterion.to(device)\n",
        "\n",
        "  counter = 0\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "      start_time = time.time()\n",
        "      \n",
        "      train_loss, train_precision, train_recall, train_f1 = train(\n",
        "          model, train_iterator, optimizer, criterion)\n",
        "\n",
        "      valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "          model, valid_iterator, criterion)\n",
        "\n",
        "      end_time = time.time()\n",
        "\n",
        "      epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "      # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n",
        "      # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de código.\n",
        "      if valid_loss < best_valid_loss:\n",
        "          best_valid_loss = valid_loss\n",
        "          torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
        "      # Si ya no mejoramos el loss de validación, terminamos de entrenar.\n",
        "\n",
        "      print(f'Epoch: {epoch+1:02}/{n_epochs} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "      print(\n",
        "          f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "      )\n",
        "      print(\n",
        "          f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "      )\n",
        "\n",
        "      # Early stopping\n",
        "      if valid_loss >= prev_loss:\n",
        "        counter += 1\n",
        "      \n",
        "      if counter == patience:\n",
        "        break\n",
        "\n",
        "      prev_loss = valid_loss\n",
        "  \n",
        "  \n",
        "  # cargar el mejor modelo entrenado.\n",
        "  model.load_state_dict(torch.load('{}.pt'.format(model_name)))\n",
        "\n",
        "  # Evaluamos el set de validación con el modelo final\n",
        "  valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "      model, valid_iterator, criterion)\n",
        "  print('------------------------------------------------')\n",
        "  print('---------------- BEST MODEL --------------------')\n",
        "  print('------------------------------------------------')\n",
        "  print(\n",
        "      f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "  )\n",
        "  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.654826Z",
          "start_time": "2020-06-23T22:25:51.103450Z"
        },
        "colab_type": "code",
        "id": "9mUOOLEWiicU",
        "colab": {}
      },
      "source": [
        "# Definimos las métricas\n",
        "\n",
        "# Noten que la evaluación solo se hace para las Named Entities (sin contar 'O').\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import warnings\n",
        "import sklearn.exceptions\n",
        "warnings.filterwarnings(\"ignore\",\n",
        "                        category=sklearn.exceptions.UndefinedMetricWarning)\n",
        "\n",
        "\n",
        "def calculate_metrics(preds, y_true, pad_idx=PAD_TAG_IDX, o_idx=O_TAG_IDX):\n",
        "    \"\"\"\n",
        "    Calcula precision, recall y f1 de cada batch.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtener el indice de la clase con probabilidad mayor. (clases)\n",
        "    y_pred = preds.argmax(dim=1, keepdim=True)\n",
        "    # Obtenemos los indices distintos de 0.\n",
        "\n",
        "    # filtramos <pad> y O para calcular los scores.\n",
        "    mask = [(y_true != o_idx) & (y_true != pad_idx)]\n",
        "    y_pred = y_pred[mask]\n",
        "    y_true = y_true[mask]\n",
        "\n",
        "    # traemos a la cpu\n",
        "    y_pred = y_pred.view(-1).to('cpu')\n",
        "    y_true = y_true.to('cpu')\n",
        "    \n",
        "    # calcular scores\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    return precision, recall, f1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hod516H1aSG2"
      },
      "source": [
        "-------------------\n",
        "\n",
        "### Modelo Baseline\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.666751Z",
          "start_time": "2020-06-23T22:25:51.656778Z"
        },
        "colab_type": "code",
        "id": "rMPL08XqaSG3",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class NER_RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim,\n",
        "                 n_layers, bidirectional, dropout, pad_idx, \n",
        "                 pretrained_weights=None, freeze_embed=False):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim,\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=pad_idx)\n",
        "        # Load pretrained weights\n",
        "        if pretrained_weights is not None:\n",
        "          # self.embedding.load_state_dict({'weight': pretrained_weights})\n",
        "          self.embedding.weight = nn.Parameter(torch.tensor(pretrained_weights).float())\n",
        "        \n",
        "          if freeze_embed:\n",
        "            self.embedding.weight.requires_grad = False\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T21:43:02.333880Z",
          "start_time": "2020-06-22T21:43:02.329861Z"
        },
        "colab_type": "text",
        "id": "cCl3530VaSG7"
      },
      "source": [
        "#### Hiperparámetros de la red\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdr8OzmVg-Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "    # Inicializamos los pesos como aleatorios\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean=0, std=0.1) \n",
        "        \n",
        "    # Seteamos como 0 los embeddings de UNK y PAD.\n",
        "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "def init_weights_pretrained(m):\n",
        "    # Inicializamos los pesos como aleatorios\n",
        "    for name, param in m.named_parameters():\n",
        "      if name != 'embedding.weight':\n",
        "        # print(name)\n",
        "        nn.init.normal_(param.data, mean=0, std=0.1) \n",
        "        \n",
        "    # Seteamos como 0 los embeddings de UNK y PAD.\n",
        "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.705684Z",
          "start_time": "2020-06-23T22:25:51.668746Z"
        },
        "colab_type": "code",
        "id": "EHdi3QdOaSG8",
        "colab": {}
      },
      "source": [
        "# tamaño del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100  # dimensión de los embeddings.\n",
        "HIDDEN_DIM = 128  # dimensión de la capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)  # número de clases\n",
        "\n",
        "N_LAYERS = 2  # número de capas.\n",
        "DROPOUT = 0.25\n",
        "BIDIRECTIONAL = False\n",
        "\n",
        "# Creamos nuestro modelo.\n",
        "baseline_model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "baseline_model_name = 'baseline'  # nombre que tendrá el modelo guardado...\n",
        "baseline_n_epochs = 10\n",
        "\n",
        "# Loss: Cross Entropy\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "baseline_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.805380Z",
          "start_time": "2020-06-23T22:25:51.751524Z"
        },
        "colab_type": "code",
        "id": "Q-G_NWFcaSHe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "f77f06dd-ad6d-48da-fea8-39f9303d06b5"
      },
      "source": [
        "model = baseline_model\n",
        "model_name = baseline_model_name\n",
        "criterion = baseline_criterion\n",
        "n_epochs = baseline_n_epochs\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NER_RNN(\n",
              "  (embedding): Embedding(26101, 100, padding_idx=1)\n",
              "  (lstm): LSTM(100, 128, num_layers=2, dropout=0.25)\n",
              "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiKRbZ7-6Q8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "38bb5187-7940-4188-fb18-1747db77ee99"
      },
      "source": [
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs=10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.440 | Train f1: 0.12 | Train precision: 0.16 | Train recall: 0.13\n",
            "\t Val. Loss: 0.313 |  Val. f1: 0.30 |  Val. precision: 0.35 | Val. recall: 0.30\n",
            "Epoch: 02/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.182 | Train f1: 0.45 | Train precision: 0.51 | Train recall: 0.45\n",
            "\t Val. Loss: 0.250 |  Val. f1: 0.48 |  Val. precision: 0.58 | Val. recall: 0.47\n",
            "Epoch: 03/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.110 | Train f1: 0.63 | Train precision: 0.68 | Train recall: 0.63\n",
            "\t Val. Loss: 0.212 |  Val. f1: 0.56 |  Val. precision: 0.62 | Val. recall: 0.56\n",
            "Epoch: 04/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.075 | Train f1: 0.73 | Train precision: 0.76 | Train recall: 0.73\n",
            "\t Val. Loss: 0.211 |  Val. f1: 0.58 |  Val. precision: 0.64 | Val. recall: 0.57\n",
            "Epoch: 05/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.057 | Train f1: 0.78 | Train precision: 0.81 | Train recall: 0.78\n",
            "\t Val. Loss: 0.224 |  Val. f1: 0.58 |  Val. precision: 0.65 | Val. recall: 0.58\n",
            "Epoch: 06/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.045 | Train f1: 0.82 | Train precision: 0.85 | Train recall: 0.82\n",
            "\t Val. Loss: 0.235 |  Val. f1: 0.58 |  Val. precision: 0.65 | Val. recall: 0.57\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.211 |  Val. f1: 0.58 | Val. precision: 0.64 | Val. recall: 0.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9spX-Hkh8YJg"
      },
      "source": [
        "### Modelos\n",
        "\n",
        "*   **[DONE]** Probar Early stopping\n",
        "*   Variar la cantidad de parámetros de la capa de embeddings.\n",
        "*   **[DONE]** Variar la cantidad de capas RNN.\n",
        "*   Variar la cantidad de parámetros de las capas de RNN.\n",
        "*   **[DONE glove, fasttext]**Inicializar la capa de embeddings con modelos pre-entrenados. (word2vec, glove, conceptnet, etc...).[Guía breve aquí](https://github.com/dccuchile/spanish-word-embeddings), [Embeddings en español aquí](https://github.com/dccuchile/spanish-word-embeddings).\n",
        "*   **[DONE]** Variar la cantidad de épocas de entrenamiento.\n",
        "*   Variar el optimizador, learning rate, batch size, usar CRF loss, etc...\n",
        "*   **[DONE]** Probar bi-direccionalidad.\n",
        "*   **[DONE]** Incluir dropout.\n",
        "*   Probar modelos de tipo GRU\n",
        "*   Probar Embedding Contextuales (les puede ser de utilidad [flair](https://github.com/flairNLP/flair))\n",
        "*   Probar modelos de transformers en español usando [Huggingface](https://github.com/huggingface/transformers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lRYOEDiQaSHK"
      },
      "source": [
        "--------------------\n",
        "### Modelo 1: Bidireccional\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.722604Z",
          "start_time": "2020-06-23T22:25:51.717615Z"
        },
        "colab_type": "code",
        "id": "c81f8ki5aSHL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "b71dc011-64f6-41eb-833b-6458e88add98"
      },
      "source": [
        "BIDIRECTIONAL = True\n",
        "model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "model.apply(init_weights)\n",
        "\n",
        "model_name = 'bi_rnn'  # nombre que tendrá el modelo guardado\n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01/10 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.357 | Train f1: 0.26 | Train precision: 0.32 | Train recall: 0.25\n",
            "\t Val. Loss: 0.246 |  Val. f1: 0.44 |  Val. precision: 0.52 | Val. recall: 0.44\n",
            "Epoch: 02/10 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.125 | Train f1: 0.61 | Train precision: 0.66 | Train recall: 0.61\n",
            "\t Val. Loss: 0.193 |  Val. f1: 0.56 |  Val. precision: 0.64 | Val. recall: 0.56\n",
            "Epoch: 03/10 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.066 | Train f1: 0.76 | Train precision: 0.79 | Train recall: 0.76\n",
            "\t Val. Loss: 0.191 |  Val. f1: 0.60 |  Val. precision: 0.65 | Val. recall: 0.61\n",
            "Epoch: 04/10 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.044 | Train f1: 0.82 | Train precision: 0.84 | Train recall: 0.82\n",
            "\t Val. Loss: 0.195 |  Val. f1: 0.62 |  Val. precision: 0.67 | Val. recall: 0.62\n",
            "Epoch: 05/10 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.030 | Train f1: 0.87 | Train precision: 0.88 | Train recall: 0.87\n",
            "\t Val. Loss: 0.216 |  Val. f1: 0.62 |  Val. precision: 0.68 | Val. recall: 0.62\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.191 |  Val. f1: 0.60 | Val. precision: 0.65 | Val. recall: 0.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rV9oLkN1aSHO"
      },
      "source": [
        "---------------\n",
        "\n",
        "### Modelo 2: Más hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaMtZ5lrseP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "8cc72825-b50e-4af5-ea84-3bde0c6316c6"
      },
      "source": [
        "model = NER_RNN(input_dim=len(TEXT.vocab),\n",
        "                embedding_dim=100,\n",
        "                hidden_dim=200,\n",
        "                output_dim=len(NER_TAGS.vocab),\n",
        "                n_layers=3,\n",
        "                bidirectional=True,\n",
        "                dropout=0.2,\n",
        "                pad_idx=PAD_IDX)\n",
        "model.apply(init_weights)\n",
        "\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')\n",
        "\n",
        "model_name = 'bigger_bi_rnn'  # nombre que tendrá el modelo guardado\n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 5,023,710 parámetros entrenables.\n",
            "Epoch: 01/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.574 | Train f1: 0.04 | Train precision: 0.06 | Train recall: 0.05\n",
            "\t Val. Loss: 0.350 |  Val. f1: 0.17 |  Val. precision: 0.25 | Val. recall: 0.18\n",
            "Epoch: 02/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.207 | Train f1: 0.36 | Train precision: 0.40 | Train recall: 0.37\n",
            "\t Val. Loss: 0.272 |  Val. f1: 0.42 |  Val. precision: 0.49 | Val. recall: 0.44\n",
            "Epoch: 03/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.109 | Train f1: 0.62 | Train precision: 0.66 | Train recall: 0.62\n",
            "\t Val. Loss: 0.233 |  Val. f1: 0.58 |  Val. precision: 0.63 | Val. recall: 0.61\n",
            "Epoch: 04/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.062 | Train f1: 0.77 | Train precision: 0.78 | Train recall: 0.76\n",
            "\t Val. Loss: 0.228 |  Val. f1: 0.61 |  Val. precision: 0.66 | Val. recall: 0.63\n",
            "Epoch: 05/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.045 | Train f1: 0.81 | Train precision: 0.83 | Train recall: 0.81\n",
            "\t Val. Loss: 0.234 |  Val. f1: 0.62 |  Val. precision: 0.67 | Val. recall: 0.63\n",
            "Epoch: 06/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.032 | Train f1: 0.85 | Train precision: 0.86 | Train recall: 0.85\n",
            "\t Val. Loss: 0.242 |  Val. f1: 0.62 |  Val. precision: 0.66 | Val. recall: 0.64\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.228 |  Val. f1: 0.61 | Val. precision: 0.66 | Val. recall: 0.63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T16:07:45.755561Z",
          "start_time": "2020-06-22T16:07:45.751571Z"
        },
        "colab_type": "text",
        "id": "Zpy3p7YaaSHT"
      },
      "source": [
        "---------------\n",
        "\n",
        "\n",
        "### Modelo 3: Mayor batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2oCe4DrvkhT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "14d572e9-4034-4890-ca47-a35cafda5673"
      },
      "source": [
        "BATCH_SIZE = 64  # disminuir si hay problemas de ram.\n",
        "\n",
        "# Usar cuda si es que está disponible.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "# Dividir datos entre entrenamiento y test\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort=False,\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.728587Z",
          "start_time": "2020-06-23T22:25:51.724596Z"
        },
        "colab_type": "code",
        "id": "KWPzETaNaSHP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "d5bc58dc-1656-4acf-e888-9f62871fa8a7"
      },
      "source": [
        "model = NER_RNN(input_dim=len(TEXT.vocab),\n",
        "                embedding_dim=100,\n",
        "                hidden_dim=200,\n",
        "                output_dim=len(NER_TAGS.vocab),\n",
        "                n_layers=3,\n",
        "                bidirectional=True,\n",
        "                dropout=0.3,\n",
        "                pad_idx=PAD_IDX)\n",
        "model.apply(init_weights)\n",
        "\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')\n",
        "\n",
        "model_name = 'bigger_bi_rnn'  # nombre que tendrá el modelo guardado\n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 5,023,710 parámetros entrenables.\n",
            "Epoch: 01/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.540 | Train f1: 0.07 | Train precision: 0.10 | Train recall: 0.07\n",
            "\t Val. Loss: 0.317 |  Val. f1: 0.25 |  Val. precision: 0.26 | Val. recall: 0.27\n",
            "Epoch: 02/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.192 | Train f1: 0.40 | Train precision: 0.45 | Train recall: 0.40\n",
            "\t Val. Loss: 0.255 |  Val. f1: 0.47 |  Val. precision: 0.57 | Val. recall: 0.45\n",
            "Epoch: 03/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.098 | Train f1: 0.67 | Train precision: 0.71 | Train recall: 0.67\n",
            "\t Val. Loss: 0.206 |  Val. f1: 0.59 |  Val. precision: 0.64 | Val. recall: 0.60\n",
            "Epoch: 04/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.060 | Train f1: 0.77 | Train precision: 0.79 | Train recall: 0.77\n",
            "\t Val. Loss: 0.210 |  Val. f1: 0.63 |  Val. precision: 0.67 | Val. recall: 0.64\n",
            "Epoch: 05/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.044 | Train f1: 0.81 | Train precision: 0.82 | Train recall: 0.81\n",
            "\t Val. Loss: 0.219 |  Val. f1: 0.64 |  Val. precision: 0.68 | Val. recall: 0.64\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.206 |  Val. f1: 0.59 | Val. precision: 0.64 | Val. recall: 0.60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN5Xuo9YwjOl",
        "colab_type": "text"
      },
      "source": [
        "---------------\n",
        "\n",
        "\n",
        "### Modelo 4: Agregar más capas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N7rqPJPtkPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NER_RNN2(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim,\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=pad_idx)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Sequential(nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                                          hidden_dim),\n",
        "                                # nn.BatchNorm1d(num_features=hidden_dim),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        # print(text.shape)\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        # print(embedded.shape)\n",
        "        \n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        # print(outputs.shape)\n",
        "\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.733572Z",
          "start_time": "2020-06-23T22:25:51.730580Z"
        },
        "colab_type": "code",
        "id": "_w0CFjA8aSHU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "4940062c-88ce-4ea7-d606-405ed1266911"
      },
      "source": [
        "model = NER_RNN2(input_dim=len(TEXT.vocab),\n",
        "                embedding_dim=100,\n",
        "                hidden_dim=200,\n",
        "                output_dim=len(NER_TAGS.vocab),\n",
        "                n_layers=3,\n",
        "                bidirectional=True,\n",
        "                dropout=0.3,\n",
        "                pad_idx=PAD_IDX)\n",
        "model.apply(init_weights)\n",
        "\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')\n",
        "\n",
        "model_name = 'bigger_bi_rnn'  # nombre que tendrá el modelo guardado\n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 5,101,910 parámetros entrenables.\n",
            "Epoch: 01/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.650 | Train f1: 0.01 | Train precision: 0.01 | Train recall: 0.01\n",
            "\t Val. Loss: 0.598 |  Val. f1: 0.01 |  Val. precision: 0.05 | Val. recall: 0.01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 02/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.254 | Train f1: nan | Train precision: nan | Train recall: nan\n",
            "\t Val. Loss: 0.294 |  Val. f1: 0.30 |  Val. precision: 0.33 | Val. recall: 0.33\n",
            "Epoch: 03/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.136 | Train f1: 0.52 | Train precision: 0.57 | Train recall: 0.53\n",
            "\t Val. Loss: 0.228 |  Val. f1: 0.56 |  Val. precision: 0.60 | Val. recall: 0.58\n",
            "Epoch: 04/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.077 | Train f1: 0.73 | Train precision: 0.75 | Train recall: 0.73\n",
            "\t Val. Loss: 0.211 |  Val. f1: 0.61 |  Val. precision: 0.65 | Val. recall: 0.62\n",
            "Epoch: 05/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.049 | Train f1: 0.80 | Train precision: 0.81 | Train recall: 0.79\n",
            "\t Val. Loss: 0.221 |  Val. f1: 0.61 |  Val. precision: 0.67 | Val. recall: 0.60\n",
            "Epoch: 06/10 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.036 | Train f1: 0.83 | Train precision: 0.84 | Train recall: 0.83\n",
            "\t Val. Loss: 0.234 |  Val. f1: 0.62 |  Val. precision: 0.66 | Val. recall: 0.63\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.211 |  Val. f1: 0.61 | Val. precision: 0.65 | Val. recall: 0.62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T21:52:04.077979Z",
          "start_time": "2020-06-23T21:52:04.072991Z"
        },
        "id": "9NNSdjcCzXzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Limpiar ram de cuda\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3la1ScFX0pk",
        "colab_type": "text"
      },
      "source": [
        "---------------\n",
        "\n",
        "\n",
        "### Modelo 5: Pesos preentrenados de GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecTD6WDjMCHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class NER_RNN3(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim,\n",
        "                 n_layers, bidirectional, dropout, pad_idx, \n",
        "                 pretrained_weights=None, freeze_embed=False):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim,\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=pad_idx)\n",
        "        # Load pretrained weights\n",
        "        if pretrained_weights is not None:\n",
        "          # self.embedding.load_state_dict({'weight': pretrained_weights})\n",
        "          self.embedding.weight = nn.Parameter(torch.tensor(pretrained_weights).float())\n",
        "        \n",
        "          if freeze_embed:\n",
        "            self.embedding.weight.requires_grad = False\n",
        "\n",
        "        # self.lstm = nn.LSTM(embedding_dim,\n",
        "        #                    hidden_dim,\n",
        "        #                    num_layers=n_layers,\n",
        "        #                    bidirectional=bidirectional, \n",
        "        #                    dropout = dropout if n_layers > 1 else 0)\n",
        "        \n",
        "        self.gru = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers=n_layers,\n",
        "                          bidirectional=bidirectional, \n",
        "                          dropout = dropout if n_layers > 1 else 0)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        # outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMHIkM72NTdr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9854cc12-19db-4179-9f8e-190df96b65aa"
      },
      "source": [
        "BATCH_SIZE = 32  # disminuir si hay problemas de ram.\n",
        "\n",
        "# Usar cuda si es que está disponible.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "# Dividir datos entre entrenamiento y test\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort=False,\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcjNm_z7f3c4",
        "colab_type": "text"
      },
      "source": [
        "#### Cargar pesos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRuPM9QlyxG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "2ee478ad-1acb-41af-b129-a17cc033cdc4"
      },
      "source": [
        "# glove pretrained embeddings\n",
        "!wget http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-02 01:50:09--  http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz\n",
            "Resolving dcc.uchile.cl (dcc.uchile.cl)... 192.80.24.11\n",
            "Connecting to dcc.uchile.cl (dcc.uchile.cl)|192.80.24.11|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz [following]\n",
            "--2020-08-02 01:50:09--  https://www.dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz\n",
            "Resolving www.dcc.uchile.cl (www.dcc.uchile.cl)... 200.9.99.213, 192.80.24.11\n",
            "Connecting to www.dcc.uchile.cl (www.dcc.uchile.cl)|200.9.99.213|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://users.dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz [following]\n",
            "--2020-08-02 01:50:10--  https://users.dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz\n",
            "Resolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 200.9.99.211, 192.80.24.4\n",
            "Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|200.9.99.211|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 949886421 (906M) [application/x-gzip]\n",
            "Saving to: ‘glove-sbwc.i25.vec.gz.1’\n",
            "\n",
            "glove-sbwc.i25.vec. 100%[===================>] 905.88M  6.35MB/s    in 2m 44s  \n",
            "\n",
            "2020-08-02 01:52:55 (5.53 MB/s) - ‘glove-sbwc.i25.vec.gz.1’ saved [949886421/949886421]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btDFEIAqY_Op",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "acd80f1a-8b00-4323-ed8d-d5f655ed9cdc"
      },
      "source": [
        "!gzip -d glove-sbwc.i25.vec.gz"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: glove-sbwc.i25.vec already exists; do you wish to overwrite (y or n)? n\n",
            "\tnot overwritten\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-V6-K-RZMRs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "5980890b-1a4b-44e3-e603-176397be1426"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "glove = KeyedVectors.load_word2vec_format('glove-sbwc.i25.vec')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-02 02:00:28,390 : loading projection weights from glove-sbwc.i25.vec\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2020-08-02 02:03:54,375 : loaded (855380, 300) matrix from glove-sbwc.i25.vec\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xoiT320X_6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c667aa65-638f-46ee-916f-fee1f783b62c"
      },
      "source": [
        "# Convert pretrained weights to matrix\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "emb_dim = 300\n",
        "glove_matrix = np.zeros((len(TEXT.vocab), emb_dim))\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(TEXT.vocab.itos):\n",
        "  word = word.translate(str.maketrans('', '', '.,')).lower()\n",
        "  try: \n",
        "    glove_matrix[i] = glove[word]\n",
        "    words_found += 1\n",
        "  except KeyError:\n",
        "    # if word is not in pretrained vocab, use random init weights\n",
        "    glove_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
        "print('Found:', words_found)\n",
        "print('Total:', len(TEXT.vocab))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found: 22930\n",
            "Total: 26101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvK9AArOf6x9",
        "colab_type": "text"
      },
      "source": [
        "#### Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AePpfSy6lwLD",
        "colab_type": "text"
      },
      "source": [
        "#### No congelando los pesos preentrenados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOdjMNrreTcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "43c85b01-7c67-4c4f-de32-c2b68abb0289"
      },
      "source": [
        "EMBEDDING_DIM = 300\n",
        "model = NER_RNN(input_dim=len(TEXT.vocab),\n",
        "                embedding_dim=EMBEDDING_DIM,\n",
        "                hidden_dim=200,\n",
        "                output_dim=len(NER_TAGS.vocab),\n",
        "                n_layers=4,\n",
        "                bidirectional=True,\n",
        "                dropout=0.5,\n",
        "                pad_idx=PAD_IDX,\n",
        "                pretrained_weights=glove_matrix,\n",
        "                freeze_embed=False)\n",
        "\n",
        "model.apply(init_weights_pretrained)\n",
        "\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')\n",
        "\n",
        "model_name = 'glove_bi_rnn'  # nombre que tendrá el modelo guardado\n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 11,527,110 parámetros entrenables.\n",
            "Epoch: 01/10 | Epoch Time: 0m 16s\n",
            "\tTrain Loss: 0.516 | Train f1: 0.08 | Train precision: 0.14 | Train recall: 0.07\n",
            "\t Val. Loss: 0.318 |  Val. f1: 0.33 |  Val. precision: 0.42 | Val. recall: 0.32\n",
            "Epoch: 02/10 | Epoch Time: 0m 16s\n",
            "\tTrain Loss: 0.201 | Train f1: 0.46 | Train precision: 0.53 | Train recall: 0.44\n",
            "\t Val. Loss: 0.209 |  Val. f1: 0.53 |  Val. precision: 0.59 | Val. recall: 0.54\n",
            "Epoch: 03/10 | Epoch Time: 0m 16s\n",
            "\tTrain Loss: 0.114 | Train f1: 0.64 | Train precision: 0.69 | Train recall: 0.63\n",
            "\t Val. Loss: 0.196 |  Val. f1: 0.60 |  Val. precision: 0.66 | Val. recall: 0.61\n",
            "Epoch: 04/10 | Epoch Time: 0m 16s\n",
            "\tTrain Loss: 0.075 | Train f1: 0.73 | Train precision: 0.76 | Train recall: 0.72\n",
            "\t Val. Loss: 0.200 |  Val. f1: 0.61 |  Val. precision: 0.66 | Val. recall: 0.62\n",
            "Epoch: 05/10 | Epoch Time: 0m 16s\n",
            "\tTrain Loss: 0.054 | Train f1: 0.79 | Train precision: 0.81 | Train recall: 0.78\n",
            "\t Val. Loss: 0.205 |  Val. f1: 0.64 |  Val. precision: 0.69 | Val. recall: 0.65\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.196 |  Val. f1: 0.60 | Val. precision: 0.66 | Val. recall: 0.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7riP8a8ElqcZ",
        "colab_type": "text"
      },
      "source": [
        "#### Congelando los pesos preentrenados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZigjrFuDlQzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "f5cd9959-a9e8-44cf-8979-db5615b5f743"
      },
      "source": [
        "EMBEDDING_DIM = 300\n",
        "model = NER_RNN(input_dim=len(TEXT.vocab),\n",
        "                embedding_dim=EMBEDDING_DIM,\n",
        "                hidden_dim=200,\n",
        "                output_dim=len(NER_TAGS.vocab),\n",
        "                n_layers=2,\n",
        "                bidirectional=True,\n",
        "                dropout=0.2,\n",
        "                pad_idx=PAD_IDX,\n",
        "                pretrained_weights=glove_matrix,\n",
        "                freeze_embed=True)\n",
        "model.apply(init_weights_pretrained)\n",
        "\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')\n",
        "\n",
        "model_name = 'glove_freeze_bi_rnn' \n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 1,770,410 parámetros entrenables.\n",
            "Epoch: 01/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.410 | Train f1: 0.24 | Train precision: 0.42 | Train recall: 0.19\n",
            "\t Val. Loss: 0.325 |  Val. f1: 0.44 |  Val. precision: 0.58 | Val. recall: 0.39\n",
            "Epoch: 02/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.228 | Train f1: 0.51 | Train precision: 0.68 | Train recall: 0.45\n",
            "\t Val. Loss: 0.256 |  Val. f1: 0.55 |  Val. precision: 0.67 | Val. recall: 0.51\n",
            "Epoch: 03/10 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.153 | Train f1: 0.64 | Train precision: 0.75 | Train recall: 0.59\n",
            "\t Val. Loss: 0.238 |  Val. f1: 0.56 |  Val. precision: 0.68 | Val. recall: 0.52\n",
            "Epoch: 04/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.108 | Train f1: 0.71 | Train precision: 0.78 | Train recall: 0.67\n",
            "\t Val. Loss: 0.225 |  Val. f1: 0.60 |  Val. precision: 0.70 | Val. recall: 0.57\n",
            "Epoch: 05/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.085 | Train f1: 0.75 | Train precision: 0.80 | Train recall: 0.72\n",
            "\t Val. Loss: 0.256 |  Val. f1: 0.60 |  Val. precision: 0.69 | Val. recall: 0.57\n",
            "Epoch: 06/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.068 | Train f1: 0.78 | Train precision: 0.82 | Train recall: 0.76\n",
            "\t Val. Loss: 0.252 |  Val. f1: 0.61 |  Val. precision: 0.70 | Val. recall: 0.59\n",
            "Epoch: 07/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.054 | Train f1: 0.79 | Train precision: 0.83 | Train recall: 0.78\n",
            "\t Val. Loss: 0.256 |  Val. f1: 0.61 |  Val. precision: 0.70 | Val. recall: 0.57\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.225 |  Val. f1: 0.60 | Val. precision: 0.70 | Val. recall: 0.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNqMPHR6lhnR",
        "colab_type": "text"
      },
      "source": [
        "---------------------------\n",
        "\n",
        "\n",
        "### Modelo 6: Pesos preentrenados de FastText"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxYFBZG4rgtk",
        "colab_type": "text"
      },
      "source": [
        "#### Cargar pesos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx1PAS7All79",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "d6d3879d-e025-4ccb-ba5c-dd2d89b43bf4"
      },
      "source": [
        "# fasttext pretrained embeddings\n",
        "!wget http://dcc.uchile.cl/~jperez/word-embeddings/fasttext-sbwc.300k.vec.gz"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-02 02:08:32--  http://dcc.uchile.cl/~jperez/word-embeddings/fasttext-sbwc.300k.vec.gz\n",
            "Resolving dcc.uchile.cl (dcc.uchile.cl)... 192.80.24.11\n",
            "Connecting to dcc.uchile.cl (dcc.uchile.cl)|192.80.24.11|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.dcc.uchile.cl/~jperez/word-embeddings/fasttext-sbwc.300k.vec.gz [following]\n",
            "--2020-08-02 02:08:33--  https://www.dcc.uchile.cl/~jperez/word-embeddings/fasttext-sbwc.300k.vec.gz\n",
            "Resolving www.dcc.uchile.cl (www.dcc.uchile.cl)... 200.9.99.213, 192.80.24.11\n",
            "Connecting to www.dcc.uchile.cl (www.dcc.uchile.cl)|200.9.99.213|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://users.dcc.uchile.cl/~jperez/word-embeddings/fasttext-sbwc.300k.vec.gz [following]\n",
            "--2020-08-02 02:08:34--  https://users.dcc.uchile.cl/~jperez/word-embeddings/fasttext-sbwc.300k.vec.gz\n",
            "Resolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 192.80.24.4, 200.9.99.211\n",
            "Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|192.80.24.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 294883037 (281M) [application/x-gzip]\n",
            "Saving to: ‘fasttext-sbwc.300k.vec.gz’\n",
            "\n",
            "fasttext-sbwc.300k. 100%[===================>] 281.22M  7.92MB/s    in 38s     \n",
            "\n",
            "2020-08-02 02:09:12 (7.36 MB/s) - ‘fasttext-sbwc.300k.vec.gz’ saved [294883037/294883037]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nvWgl-kmcVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gzip -d fasttext-sbwc.300k.vec.gz"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5FoSnJcwl_cL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "c2c545ce-ac79-4eb0-cad8-ac8468fd73d0"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "fast = KeyedVectors.load_word2vec_format('fasttext-sbwc.300k.vec')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-02 02:09:21,971 : loading projection weights from fasttext-sbwc.300k.vec\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2020-08-02 02:10:32,274 : loaded (300000, 300) matrix from fasttext-sbwc.300k.vec\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S4MhvoAYl_cY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1a747384-0f71-422d-86cc-d5a64bc65426"
      },
      "source": [
        "# Convert pretrained weights to matrix\n",
        "import numpy as np\n",
        "\n",
        "emb_dim = 300\n",
        "fast_matrix = np.zeros((len(TEXT.vocab), emb_dim))\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(TEXT.vocab.itos):\n",
        "  word = word.translate(str.maketrans('', '', '.,')).lower()\n",
        "  try: \n",
        "    fast_matrix[i] = fast[word]\n",
        "    words_found += 1\n",
        "  except KeyError:\n",
        "    # if word is not in pretrained vocab, use random init weights\n",
        "    fast_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
        "print('Found:', words_found)\n",
        "print('Total:', len(TEXT.vocab))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found: 22485\n",
            "Total: 26101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2Qcxrnjriuv",
        "colab_type": "text"
      },
      "source": [
        "#### Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e4KoAy-siNh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "5421954c-ae3a-44a2-f2c6-db84ca96fa8c"
      },
      "source": [
        "# No congelando los pesos preentrenados\n",
        "\n",
        "EMBEDDING_DIM = 300\n",
        "model = NER_RNN(input_dim=len(TEXT.vocab),\n",
        "                embedding_dim=EMBEDDING_DIM,\n",
        "                hidden_dim=200,\n",
        "                output_dim=len(NER_TAGS.vocab),\n",
        "                n_layers=2,\n",
        "                bidirectional=True,\n",
        "                dropout=0.5,\n",
        "                pad_idx=PAD_IDX,\n",
        "                pretrained_weights=fast_matrix,\n",
        "                freeze_embed=False)\n",
        "model.apply(init_weights_pretrained)\n",
        "\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')\n",
        "\n",
        "model_name = 'fast_bi_rnn'  # nombre que tendrá el modelo guardado\n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 9,600,710 parámetros entrenables.\n",
            "Epoch: 01/10 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.253 | Train f1: 0.46 | Train precision: 0.53 | Train recall: 0.43\n",
            "\t Val. Loss: 0.183 |  Val. f1: 0.59 |  Val. precision: 0.66 | Val. recall: 0.59\n",
            "Epoch: 02/10 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.081 | Train f1: 0.73 | Train precision: 0.76 | Train recall: 0.72\n",
            "\t Val. Loss: 0.195 |  Val. f1: 0.59 |  Val. precision: 0.67 | Val. recall: 0.57\n",
            "Epoch: 03/10 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.052 | Train f1: 0.80 | Train precision: 0.82 | Train recall: 0.79\n",
            "\t Val. Loss: 0.196 |  Val. f1: 0.65 |  Val. precision: 0.69 | Val. recall: 0.66\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.183 |  Val. f1: 0.59 | Val. precision: 0.66 | Val. recall: 0.59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSDuEMG0rfjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "d8f41b35-04a6-4634-ad98-f08ab2b3a0c6"
      },
      "source": [
        "# Congelando los pesos preentrenados\n",
        "\n",
        "EMBEDDING_DIM = 300\n",
        "model = NER_RNN(input_dim=len(TEXT.vocab),\n",
        "                embedding_dim=EMBEDDING_DIM,\n",
        "                hidden_dim=200,\n",
        "                output_dim=len(NER_TAGS.vocab),\n",
        "                n_layers=2,\n",
        "                bidirectional=True,\n",
        "                dropout=0.5,\n",
        "                pad_idx=PAD_IDX,\n",
        "                pretrained_weights=fast_matrix,\n",
        "                freeze_embed=True)\n",
        "model.apply(init_weights_pretrained)\n",
        "\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')\n",
        "\n",
        "model_name = 'fast_freeze_bi_rnn' \n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 1,770,410 parámetros entrenables.\n",
            "Epoch: 01/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.464 | Train f1: 0.17 | Train precision: 0.36 | Train recall: 0.12\n",
            "\t Val. Loss: 0.382 |  Val. f1: 0.33 |  Val. precision: 0.52 | Val. recall: 0.28\n",
            "Epoch: 02/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.319 | Train f1: 0.36 | Train precision: 0.57 | Train recall: 0.29\n",
            "\t Val. Loss: 0.314 |  Val. f1: 0.45 |  Val. precision: 0.61 | Val. recall: 0.39\n",
            "Epoch: 03/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.266 | Train f1: 0.46 | Train precision: 0.66 | Train recall: 0.39\n",
            "\t Val. Loss: 0.301 |  Val. f1: 0.47 |  Val. precision: 0.63 | Val. recall: 0.42\n",
            "Epoch: 04/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.232 | Train f1: 0.52 | Train precision: 0.69 | Train recall: 0.45\n",
            "\t Val. Loss: 0.261 |  Val. f1: 0.52 |  Val. precision: 0.66 | Val. recall: 0.48\n",
            "Epoch: 05/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.211 | Train f1: 0.56 | Train precision: 0.71 | Train recall: 0.49\n",
            "\t Val. Loss: 0.254 |  Val. f1: 0.54 |  Val. precision: 0.67 | Val. recall: 0.50\n",
            "Epoch: 06/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.192 | Train f1: 0.59 | Train precision: 0.73 | Train recall: 0.53\n",
            "\t Val. Loss: 0.242 |  Val. f1: 0.55 |  Val. precision: 0.69 | Val. recall: 0.51\n",
            "Epoch: 07/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.181 | Train f1: 0.61 | Train precision: 0.74 | Train recall: 0.54\n",
            "\t Val. Loss: 0.248 |  Val. f1: 0.56 |  Val. precision: 0.68 | Val. recall: 0.51\n",
            "Epoch: 08/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.178 | Train f1: 0.61 | Train precision: 0.74 | Train recall: 0.55\n",
            "\t Val. Loss: 0.251 |  Val. f1: 0.57 |  Val. precision: 0.68 | Val. recall: 0.53\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.242 |  Val. f1: 0.55 | Val. precision: 0.69 | Val. recall: 0.51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0fu8brJnq2t",
        "colab_type": "text"
      },
      "source": [
        "----------------\n",
        "\n",
        "### Modelo 7: GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN5L34OLnp97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class GRU_RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim,\n",
        "                 n_layers, bidirectional, dropout, pad_idx, \n",
        "                 pretrained_weights=None, freeze_embed=False):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim,\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=pad_idx)\n",
        "        # Load pretrained weights\n",
        "        if pretrained_weights is not None:\n",
        "          # self.embedding.load_state_dict({'weight': pretrained_weights})\n",
        "          self.embedding.weight = nn.Parameter(torch.tensor(pretrained_weights).float())\n",
        "        \n",
        "          if freeze_embed:\n",
        "            self.embedding.weight.requires_grad = False\n",
        "\n",
        "        self.gru = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers=n_layers,\n",
        "                          bidirectional=bidirectional, \n",
        "                          dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMdyfXg1o9lR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "4aabab4b-4439-4ec4-c717-794f98e96b0a"
      },
      "source": [
        "# Congelando los pesos preentrenados\n",
        "\n",
        "EMBEDDING_DIM = 300\n",
        "model = GRU_RNN(input_dim=len(TEXT.vocab),\n",
        "                embedding_dim=EMBEDDING_DIM,\n",
        "                hidden_dim=200,\n",
        "                output_dim=len(NER_TAGS.vocab),\n",
        "                n_layers=2,\n",
        "                bidirectional=True,\n",
        "                dropout=0.5,\n",
        "                pad_idx=PAD_IDX,\n",
        "                pretrained_weights=fast_matrix,\n",
        "                freeze_embed=False)\n",
        "model.apply(init_weights_pretrained)\n",
        "\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')\n",
        "\n",
        "model_name = 'bi_gru' \n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 9,159,110 parámetros entrenables.\n",
            "Epoch: 01/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.314 | Train f1: 0.42 | Train precision: 0.53 | Train recall: 0.39\n",
            "\t Val. Loss: 0.199 |  Val. f1: 0.59 |  Val. precision: 0.67 | Val. recall: 0.57\n",
            "Epoch: 02/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.090 | Train f1: 0.72 | Train precision: 0.76 | Train recall: 0.70\n",
            "\t Val. Loss: 0.201 |  Val. f1: 0.63 |  Val. precision: 0.71 | Val. recall: 0.61\n",
            "Epoch: 03/10 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.053 | Train f1: 0.80 | Train precision: 0.82 | Train recall: 0.79\n",
            "\t Val. Loss: 0.209 |  Val. f1: 0.64 |  Val. precision: 0.70 | Val. recall: 0.63\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.199 |  Val. f1: 0.59 | Val. precision: 0.67 | Val. recall: 0.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uF1ysw_Kw6zz"
      },
      "source": [
        "\n",
        "## Predecir datos para la competencia\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:31:56.776563Z",
          "start_time": "2020-06-23T22:31:39.654525Z"
        },
        "colab_type": "code",
        "id": "1RBs3UU4wLk3",
        "colab": {}
      },
      "source": [
        "def predict_labels(model, iterator, criterion, fields=fields):\n",
        "\n",
        "    # Extraemos los vocabularios.\n",
        "    text_field = fields[0][1]\n",
        "    nertags_field = fields[1][1]\n",
        "    tags_vocab = nertags_field.vocab.itos\n",
        "    words_vocab = text_field.vocab.itos\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            text_batch = batch.text\n",
        "            text_batch = torch.transpose(text_batch, 0, 1).tolist()\n",
        "\n",
        "            # Predecir los tags de las sentences del batch\n",
        "            predictions_batch = model(batch.text)\n",
        "            predictions_batch = torch.transpose(predictions_batch, 0, 1)\n",
        "\n",
        "            # por cada oración predicha:\n",
        "            for sentence, sentence_prediction in zip(text_batch,\n",
        "                                                     predictions_batch):\n",
        "                for word_idx, word_predictions in zip(sentence,\n",
        "                                                      sentence_prediction):\n",
        "                    # Obtener el indice del tag con la probabilidad mas alta.\n",
        "                    argmax_index = word_predictions.topk(1)[1]\n",
        "\n",
        "                    current_tag = tags_vocab[argmax_index]\n",
        "                    # Obtenemos la palabra\n",
        "                    current_word = words_vocab[word_idx]\n",
        "\n",
        "                    if current_word != '<pad>':\n",
        "                        predictions.append([current_word, current_tag])\n",
        "\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "predictions = predict_labels(model, test_iterator, criterion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YwQp1Ru8Oht8"
      },
      "source": [
        "### Generar el archivo para la submission\n",
        "\n",
        "No hay problema si aparecen unk en la salida. Estos no son relevantes para evaluarlos, usamos solo los tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:33:41.845955Z",
          "start_time": "2020-06-23T22:33:41.731717Z"
        },
        "colab_type": "code",
        "id": "RPfZkjJGkWyq",
        "colab": {}
      },
      "source": [
        "import os, shutil\n",
        "\n",
        "if (os.path.isfile('./predictions.zip')):\n",
        "    os.remove('./predictions.zip')\n",
        "\n",
        "if (not os.path.isdir('./predictions')):\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "else:\n",
        "    # Eliminar predicciones anteriores:\n",
        "    shutil.rmtree('./predictions')\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "f = open('predictions/predictions.txt', 'w')\n",
        "for word, tag in predictions:\n",
        "    f.write(word + ' ' + tag + '\\n')\n",
        "f.write('\\n')\n",
        "f.close()\n",
        "\n",
        "a = shutil.make_archive('predictions', 'zip', './predictions')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T21:49:19.575711Z",
          "start_time": "2020-06-23T21:49:19.100486Z"
        },
        "colab_type": "code",
        "id": "k2PqvJAmTFWR",
        "colab": {}
      },
      "source": [
        "# A veces no funciona a la primera. Ejecutar mas de una vez para obtener el archivo...\n",
        "from google.colab import files\n",
        "files.download('predictions.zip')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LZEWJXrNaSIf"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "Con este trabajo, se realiza una exploración de redes recurrentes para clasificación de palabras en una frase. Se utilizan modelos LSTM y GRU, además de utilizar embeddings de palabras pre-entrenados, con éxito relativo. Ya que no se logra una clasificación destacable en la competencia, sin embargo, se logra superar el baseline con un modelo de LSTM, hiperparámetros ajustados levemente, y con embeddings pre-entrenados, en este caso, el mejor fue con GloVe.\n",
        "\n",
        "Como trabajo futuro, se podría variar la arquitectura de la red, agregando más capas o skip-connection que podría mejorar el rendimiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-Ybjxwp0k1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}