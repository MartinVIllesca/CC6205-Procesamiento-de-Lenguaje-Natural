{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Tarea_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartinVIllesca/CC6205-Procesamiento-de-Lenguaje-Natural/blob/master/Tarea2/Tarea_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z0tyIsliieNr"
      },
      "source": [
        "# Tarea 2 - Named Entity Recognition\n",
        "\n",
        "----------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T15:21:15.416464Z",
          "start_time": "2020-06-22T15:21:15.411478Z"
        },
        "colab_type": "text",
        "id": "X3QUWWoWaSE3"
      },
      "source": [
        "- **Nombre:** Martín Valderrama, Jou-Hui Ho\n",
        "\n",
        "- **Usuario o nombre de equipo en Codalab:** pibjou\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W_dxGEs3iiau"
      },
      "source": [
        "\n",
        "## Introducción a la tarea\n",
        "\n",
        "### Objetivo\n",
        "\n",
        "\n",
        "El objetivo de esta tarea es resolver una de las tasks mas importantes de Sequence Labelling: [Named Entity Recognition (NER)](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf). \n",
        "\n",
        "\n",
        "Esperamos que (por lo menos) utilizen Redes Neuronales Recurrentes (RNN) para resolverla. Nuevamente, hay total libertad para utilizar software y los modelos que deseen, siempre y cuando estos no traigan los modelos ya implementados (como el caso de spacy).\n",
        "\n",
        "\n",
        "**Named Entity Recognition (NER)**\n",
        "\n",
        "Esta tarea consiste en localizar y clasificar los tokens de una oración que representen entidades nombradas. Es decir, tokens que simbolicen (1) **personas**, (2) **organizaciones**, (3) **lugares** y (4) **adjetivos, eventos y otras entidades que no entren en las categorías anteriores** deberán ser taggeados como (1) **PER**, (2) **ORG**, (3) **LOC** y (4) **MISC** respectivamente. Adicionalmente, dado que existen entidades representadas en más de un token (como La Serena), se utiliza la notación BIO como prefijo al tag: Beginning, Inside, Outside. Es decir, si encuentro una entidad, el primer token etiquetado será precedido por B, el segundo por I y los n restantes por I. Por otra parte, si el token no representa ninguna entidad nombrada, se representa por O. Un ejemplo de esto es:\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "```\n",
        "Felipe B-PER\n",
        "Bravo I-PER\n",
        "es O\n",
        "el O\n",
        "profesor O\n",
        "de O\n",
        "PLN B-MISC\n",
        "de O\n",
        "la O\n",
        "Universidad B-ORG\n",
        "de I-ORG\n",
        "Chile I-ORG\n",
        ". O\n",
        "```\n",
        "\n",
        "Estos links son los más indicados para comenzar:\n",
        "\n",
        "-  [Tagging, and Hidden Markov Models ](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf) (slides by Michael Collins), [notes](http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf), [video 1](https://youtu.be/-ngfOZz8yK0), [video 2](https://youtu.be/PLoLKQwkONw), [video 3](https://youtu.be/aaa5Qoi8Vco), [video 4](https://youtu.be/4pKWIDkF_6Y)       \n",
        "-  [Recurrent Neural Networks](slides/NLP-RNN.pdf) | [video 1](https://youtu.be/BmhjUkzz3nk), [video 2](https://youtu.be/z43YFR1iIvk), [video 3](https://youtu.be/7L5JxQdwNJk)\n",
        "\n",
        "\n",
        "Recuerden que todo el material se encuentra disponible en el [github del curso](https://github.com/dccuchile/CC6205)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V5BBxJWQaSE-"
      },
      "source": [
        "**Link a la competencia:  https://competitions.codalab.org/competitions/25302?secret_key=690406c7-b3b0-4092-8694-d08d7991ca94**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4HfZqQ-_aSFE"
      },
      "source": [
        "### Reporte\n",
        "\n",
        "Este debe cumplir la siguiente estructura:\n",
        "\n",
        "1.\t**Introducción**: Presentar brevemente el problema a resolver, los modelos utilizados en el desarrollo de la tarea y conclusiones obtenidas. (0.5 Puntos)\n",
        "\n",
        "2.\t**Modelos**: Describir brevemente los modelos, métodos y hiperparámetros utilizados. (1.0 puntos)\n",
        "\n",
        "4.\t**Métricas de evaluación**: Describir las métricas utilizadas en la evaluación indicando que miden y cuál es su interpretación en este problema en particular. (0.5 puntos)\n",
        "\n",
        "5.\t**Experimentos**: Reportar todos sus experimentos y código en esta sección. Comparar los resultados obtenidos utilizando diferentes modelos. ¡Es vital haber realizado varios experimentos para sacar una buena nota! (3.0 puntos)\n",
        "\n",
        "6.\t**Conclusiones**: Discutir resultados, proponer trabajo futuro. (1.0 punto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f7X2FruyaSFG"
      },
      "source": [
        "\n",
        "-----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PzQlYlmGaSFH"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UbA1EmhCaSFI"
      },
      "source": [
        "## Modelos \n",
        "\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AaVhZ5iaaSFK"
      },
      "source": [
        "## Métricas de evaluación\n",
        "\n",
        "- **Precision:** ...\n",
        "- **Recall:** ...\n",
        "- **F1 score:** ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T15:44:52.175773Z",
          "start_time": "2020-06-22T15:44:52.172782Z"
        },
        "colab_type": "text",
        "id": "uFM-wNt8aSFM"
      },
      "source": [
        "## Experimentos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LMgKjfYC_Go-"
      },
      "source": [
        "###  Carga de datos y Preprocesamiento\n",
        "\n",
        "El proceso será el siguiente: \n",
        "\n",
        "1. Descargar los datos desde github y examinarlos.\n",
        "2. Definir los campos (`fields`) que cargaremos desde los archivos.\n",
        "3. Cargar los datasets.\n",
        "4. Crear el vocabulario.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:24:52.392908Z",
          "start_time": "2020-06-23T22:24:50.641641Z"
        },
        "colab_type": "code",
        "id": "27csY87GaSFO",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "3c17b60b-c405-4e22-f81e-1bebed072ca9"
      },
      "source": [
        "# Instalar torchtext (en codalab) - Descomentar.\n",
        "!pip3 install --upgrade torchtext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 30.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 25.9MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 34.7MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 39.8MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 30.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 33.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 27.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 19.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 21.0MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92kB 22.4MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 24.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 112kB 24.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 122kB 24.0MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 24.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 143kB 24.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 153kB 24.0MB/s eta 0:00:01\r\u001b[K     |████▉                           | 163kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 174kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 184kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 194kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 204kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 215kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 225kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 235kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 245kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 256kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 266kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 276kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 286kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 296kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 307kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 317kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 327kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 337kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 348kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 358kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 368kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 378kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 389kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 399kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 409kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 419kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 430kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 440kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 450kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 460kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 471kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 481kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 491kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 501kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 512kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 522kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 532kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 542kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 552kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 563kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 573kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 583kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 593kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 604kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 614kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 624kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 634kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 645kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 655kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 665kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 675kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 686kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 696kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 706kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 716kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 727kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 737kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 747kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 757kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 768kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 778kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 788kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 798kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 808kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 819kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 829kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 839kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 849kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 860kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 870kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 880kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 890kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 901kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 911kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 921kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 931kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 942kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 952kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 962kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 972kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 983kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 993kB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.0MB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.0MB 24.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 24.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 24.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.5.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext) (0.16.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.91 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:24:53.086354Z",
          "start_time": "2020-06-23T22:24:52.394902Z"
        },
        "colab_type": "code",
        "id": "ng7wRGEyawjM",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data, datasets\n",
        "\n",
        "# Garantizar reproducibilidad \n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:49.789218Z",
          "start_time": "2020-06-23T22:24:53.088871Z"
        },
        "colab_type": "code",
        "id": "lbT0g_kC18Jb",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/Data/train_NER_esp.txt -nc # Dataset de Entrenamiento\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/Data/val_NER_esp.txt -nc    # Dataset de Validación (Para probar y ajustar el modelo)\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/Data/test_NER_esp.txt -nc  # Dataset de la Competencia. Estos datos solo contienen los tokens. ¡¡SON LOS QUE DEBEN SER PREDICHOS!!"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uMud7YGMBZvg"
      },
      "source": [
        "####  Fields\n",
        "\n",
        "Un `field`:\n",
        "\n",
        "* Define un tipo de datos junto con instrucciones para convertir el texto a Tensor.\n",
        "* Contiene un objeto `Vocab` que contiene el vocabulario (palabras posibles que puede tomar ese campo).\n",
        "* Contiene otros parámetros relacionados con la forma en que se debe numericalizar un tipo de datos, como un método de tokenización y el tipo de Tensor que se debe producir.\n",
        "\n",
        "\n",
        "Analizemos el siguiente cuadro el cual contiene un ejemplo cualquiera de entrenamiento:\n",
        "\n",
        "\n",
        "```\n",
        "El O\n",
        "Abogado B-PER\n",
        "General I-PER\n",
        "del I-PER\n",
        "Estado I-PER\n",
        ", O\n",
        "Daryl B-PER\n",
        "Williams I-PER\n",
        "```\n",
        "\n",
        "Cada linea contiene una palabra y su clase. Para que `torchtext` pueda cargar estos datos, debemos definir como va a leer y separar los componentes de cada una de las lineas.\n",
        "Para esto, definiremos un field para cada uno de esos componentes: Las palabras (`TEXT`) y los NER_TAGS (`clase`).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:49.795126Z",
          "start_time": "2020-06-23T22:25:49.791108Z"
        },
        "colab_type": "code",
        "id": "3DcM_IjgCdzz",
        "colab": {}
      },
      "source": [
        "# Primer Field: TEXT. Representan los tokens de la secuencia\n",
        "TEXT = data.Field(lower=False) \n",
        "\n",
        "# Segundo Field: NER_TAGS. Representan los Tags asociados a cada palabra.\n",
        "NER_TAGS = data.Field(unk_token=None)\n",
        "\n",
        "fields = ((\"text\", TEXT), (\"nertags\", NER_TAGS))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xCKTJOdgC5eC"
      },
      "source": [
        "####  SequenceTaggingDataset\n",
        "\n",
        "`SequenceTaggingDataset` es una clase de torchtext diseñada para contener datasets de sequence labelling. \n",
        "Los ejemplos que se guarden en una instancia de estos serán arreglos de palabras pareados con sus respectivos tags.\n",
        "Por ejemplo, para Part-of-speech tagging:\n",
        "\n",
        "[I, love, PyTorch, .] estará pareado con [PRON, VERB, PROPN, PUNCT]\n",
        "\n",
        "\n",
        "La idea es que usando los fields que definimos antes, le indiquemos a la clase cómo cargar los datasets de prueba, validación y test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.294370Z",
          "start_time": "2020-06-23T22:25:49.797092Z"
        },
        "colab_type": "code",
        "id": "HsHdGml62J21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "249fc383-073d-4e29-fbf8-42314037dc88"
      },
      "source": [
        "train_data, valid_data, test_data = datasets.SequenceTaggingDataset.splits(\n",
        "    path=\"./\",\n",
        "    train=\"train_NER_esp.txt\",\n",
        "    validation=\"val_NER_esp.txt\",\n",
        "    test=\"test_NER_esp.txt\",\n",
        "    fields=fields,\n",
        "    encoding=\"iso-8859-1\",\n",
        "    separator=\" \"\n",
        ")\n",
        "\n",
        "print(f\"Numero de ejemplos de entrenamiento: {len(train_data)}\")\n",
        "print(f\"Número de ejemplos de validación: {len(valid_data)}\")\n",
        "print(f\"Número de ejemplos de test (competencia): {len(test_data)}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de ejemplos de entrenamiento: 8323\n",
            "Número de ejemplos de validación: 1915\n",
            "Número de ejemplos de test (competencia): 1517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.317313Z",
          "start_time": "2020-06-23T22:25:50.303361Z"
        },
        "colab_type": "code",
        "id": "T023Ld4RaSF4",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "08d01f56-0ae1-4138-88f7-54339bc6a9ea"
      },
      "source": [
        "# # Un ejemplo\n",
        "import random\n",
        "random_item_idx = random.randint(0, len(train_data))\n",
        "random_example = train_data.examples[random_item_idx]\n",
        "list(zip(random_example.text, random_example.nertags))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Dentro', 'O'),\n",
              " ('del', 'O'),\n",
              " ('Año', 'B-MISC'),\n",
              " ('Velázquez', 'I-MISC'),\n",
              " ('ha', 'O'),\n",
              " ('sido', 'O'),\n",
              " ('comisario', 'O'),\n",
              " ('de', 'O'),\n",
              " ('la', 'O'),\n",
              " ('muestra', 'O'),\n",
              " ('\"', 'B-MISC'),\n",
              " ('Velázquez', 'I-MISC'),\n",
              " ('en', 'I-MISC'),\n",
              " ('los', 'I-MISC'),\n",
              " ('museos', 'I-MISC'),\n",
              " ('de', 'I-MISC'),\n",
              " ('Nueva', 'I-MISC'),\n",
              " ('York', 'I-MISC'),\n",
              " ('\"', 'I-MISC'),\n",
              " ('de', 'O'),\n",
              " ('la', 'O'),\n",
              " ('colección', 'O'),\n",
              " ('Frick', 'B-MISC'),\n",
              " ('y', 'O'),\n",
              " ('de', 'O'),\n",
              " ('la', 'O'),\n",
              " ('exposición', 'O'),\n",
              " ('\"', 'B-MISC'),\n",
              " ('Velázquez,', 'I-MISC'),\n",
              " ('Rubens.', 'I-MISC'),\n",
              " ('van', 'I-MISC'),\n",
              " ('Dyck.', 'I-MISC'),\n",
              " ('Pintores', 'I-MISC'),\n",
              " ('cortesanos', 'I-MISC'),\n",
              " ('del', 'I-MISC'),\n",
              " ('siglo', 'I-MISC'),\n",
              " ('XVIII', 'I-MISC'),\n",
              " ('\"', 'I-MISC'),\n",
              " ('en', 'O'),\n",
              " ('el', 'O'),\n",
              " ('Museo', 'B-LOC'),\n",
              " ('del', 'I-LOC'),\n",
              " ('Prado', 'I-LOC'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2l05KYy5FSUy"
      },
      "source": [
        "#### Construir los vocabularios para el texto y las etiquetas\n",
        "\n",
        "Los vocabularios son los obbjetos que contienen todos los tokens (de entrenamiento) posibles para ambos fields.\n",
        "El siguiente paso consiste en construirlos. Para esto, hacemos uso del método `Field.build_vocab` sobre cada uno de nuestros `fields`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.445968Z",
          "start_time": "2020-06-23T22:25:50.320305Z"
        },
        "colab_type": "code",
        "id": "PBhp7WICiibL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "bfa98bb3-630a-4b77-fd92-87ba0d6d4b7e"
      },
      "source": [
        "TEXT.build_vocab(train_data)\n",
        "NER_TAGS.build_vocab(train_data)\n",
        "\n",
        "print(f\"Tokens únicos en TEXT: {len(TEXT.vocab)}\")\n",
        "print(f\"Tokens únicos en NER_TAGS: {len(NER_TAGS.vocab)}\")\n",
        "\n",
        "#Veamos las posibles etiquetas que hemos cargado:\n",
        "print(NER_TAGS.vocab.itos)\n",
        "\n",
        "# Tokens mas frecuentes\n",
        "TEXT.vocab.freqs.most_common(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokens únicos en TEXT: 26101\n",
            "Tokens únicos en NER_TAGS: 10\n",
            "['<pad>', 'O', 'B-ORG', 'I-ORG', 'B-LOC', 'B-PER', 'I-PER', 'I-MISC', 'B-MISC', 'I-LOC']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('de', 17657),\n",
              " (',', 14716),\n",
              " ('la', 9571),\n",
              " ('que', 7516),\n",
              " ('.', 7263),\n",
              " ('el', 6905),\n",
              " ('en', 6484),\n",
              " ('\"', 5691),\n",
              " ('y', 5336),\n",
              " ('a', 4304)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.479897Z",
          "start_time": "2020-06-23T22:25:50.475889Z"
        },
        "id": "3T6zXWK8zXxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seteamos algunas variables que nos serán de utilidad mas adelante...\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "PAD_TAG_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "O_TAG_IDX = NER_TAGS.vocab.stoi['O']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:50.490885Z",
          "start_time": "2020-06-23T22:25:50.481873Z"
        },
        "colab_type": "code",
        "id": "tuXOsbJUiibh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "0879a172-8418-4f75-d797-00e412af95f9"
      },
      "source": [
        "# Frecuencia de los Tags\n",
        "\n",
        "def tag_percentage(tag_counts):\n",
        "    \n",
        "    total_count = sum([count for tag, count in tag_counts])\n",
        "    tag_counts_percentages = [(tag, count, count/total_count) for tag, count in tag_counts]\n",
        "  \n",
        "    return tag_counts_percentages\n",
        "\n",
        "print(\"Tag Ocurrencia Porcentaje\\n\")\n",
        "\n",
        "for tag, count, percent in tag_percentage(NER_TAGS.vocab.freqs.most_common()):\n",
        "    print(f\"{tag}\\t{count}\\t{percent*100:4.1f}%\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tag Ocurrencia Porcentaje\n",
            "\n",
            "O\t231920\t87.6%\n",
            "B-ORG\t7390\t 2.8%\n",
            "I-ORG\t4992\t 1.9%\n",
            "B-LOC\t4913\t 1.9%\n",
            "B-PER\t4321\t 1.6%\n",
            "I-PER\t3903\t 1.5%\n",
            "I-MISC\t3212\t 1.2%\n",
            "B-MISC\t2173\t 0.8%\n",
            "I-LOC\t1891\t 0.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T21:44:17.730460Z",
          "start_time": "2020-06-22T21:44:17.724482Z"
        },
        "colab_type": "text",
        "id": "y4wPiydnaSGs"
      },
      "source": [
        "#### Configuramos pytorch y dividimos los datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.101455Z",
          "start_time": "2020-06-23T22:25:50.492843Z"
        },
        "colab_type": "code",
        "id": "uB7cwLWpaSGs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "49222f66-d7af-462f-de60-68e863b4a736"
      },
      "source": [
        "BATCH_SIZE = 16  # disminuir si hay problemas de ram.\n",
        "\n",
        "# Usar cuda si es que está disponible.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "# Dividir datos entre entrenamiento y test\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort=False,\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ISH58OP2Efn",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:54.515194Z",
          "start_time": "2020-06-23T22:25:54.505221Z"
        },
        "colab_type": "code",
        "id": "DV6YLt0oiicW",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        text = batch.text\n",
        "        tags = batch.nertags\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        predictions = model(text)\n",
        "\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "        #tags = [sent len, batch size]\n",
        "\n",
        "        # Reordenamos los datos para calcular la loss\n",
        "        predictions = predictions.view(-1, predictions.shape[-1])\n",
        "        tags = tags.view(-1)\n",
        "\n",
        "        #predictions = [sent len * batch size, output dim]\n",
        "        #tags = [sent len * batch size]\n",
        "\n",
        "        loss = criterion(predictions, tags)\n",
        "        precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_precision += precision\n",
        "        epoch_recall += recall\n",
        "        epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(\n",
        "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text = batch.text\n",
        "            tags = batch.nertags\n",
        "\n",
        "            predictions = model(text)\n",
        "\n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = tags.view(-1)\n",
        "\n",
        "            loss = criterion(predictions, tags)\n",
        "            precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_precision += precision\n",
        "            epoch_recall += recall\n",
        "            epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(\n",
        "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T21:49:02.524817Z",
          "start_time": "2020-06-23T21:47:09.863026Z"
        },
        "colab_type": "code",
        "id": "iK5lQqpviicf",
        "colab": {}
      },
      "source": [
        "def run_training(model, train_iterator, valid_iterator, optimizer, criterion, \n",
        "                 n_epochs, patience=2):\n",
        "  best_valid_loss = float('inf')\n",
        "  prev_loss = float('inf')\n",
        "\n",
        "  # Enviamos el modelo y la loss a cuda (en el caso en que esté disponible)\n",
        "  model = model.to(device)\n",
        "  criterion = criterion.to(device)\n",
        "\n",
        "  counter = 0\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "      start_time = time.time()\n",
        "      \n",
        "      train_loss, train_precision, train_recall, train_f1 = train(\n",
        "          model, train_iterator, optimizer, criterion)\n",
        "\n",
        "      valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "          model, valid_iterator, criterion)\n",
        "\n",
        "      end_time = time.time()\n",
        "\n",
        "      epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "      # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n",
        "      # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de código.\n",
        "      if valid_loss < best_valid_loss:\n",
        "          best_valid_loss = valid_loss\n",
        "          torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
        "      # Si ya no mejoramos el loss de validación, terminamos de entrenar.\n",
        "\n",
        "      print(f'Epoch: {epoch+1:02}/{n_epochs} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "      print(\n",
        "          f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "      )\n",
        "      print(\n",
        "          f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "      )\n",
        "\n",
        "      # Early stopping\n",
        "      if valid_loss >= prev_loss:\n",
        "        counter += 1\n",
        "      \n",
        "      if counter == patience:\n",
        "        break\n",
        "\n",
        "      prev_loss = valid_loss\n",
        "  \n",
        "  \n",
        "  # cargar el mejor modelo entrenado.\n",
        "  model.load_state_dict(torch.load('{}.pt'.format(model_name)))\n",
        "\n",
        "  # Evaluamos el set de validación con el modelo final\n",
        "  valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "      model, valid_iterator, criterion)\n",
        "  print('------------------------------------------------')\n",
        "  print('---------------- BEST MODEL --------------------')\n",
        "  print('------------------------------------------------')\n",
        "  print(\n",
        "      f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "  )\n",
        "  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.654826Z",
          "start_time": "2020-06-23T22:25:51.103450Z"
        },
        "colab_type": "code",
        "id": "9mUOOLEWiicU",
        "colab": {}
      },
      "source": [
        "# Definimos las métricas\n",
        "\n",
        "# Noten que la evaluación solo se hace para las Named Entities (sin contar 'O').\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import warnings\n",
        "import sklearn.exceptions\n",
        "warnings.filterwarnings(\"ignore\",\n",
        "                        category=sklearn.exceptions.UndefinedMetricWarning)\n",
        "\n",
        "\n",
        "def calculate_metrics(preds, y_true, pad_idx=PAD_TAG_IDX, o_idx=O_TAG_IDX):\n",
        "    \"\"\"\n",
        "    Calcula precision, recall y f1 de cada batch.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtener el indice de la clase con probabilidad mayor. (clases)\n",
        "    y_pred = preds.argmax(dim=1, keepdim=True)\n",
        "    # Obtenemos los indices distintos de 0.\n",
        "\n",
        "    # filtramos <pad> y O para calcular los scores.\n",
        "    mask = [(y_true != o_idx) & (y_true != pad_idx)]\n",
        "    y_pred = y_pred[mask]\n",
        "    y_true = y_true[mask]\n",
        "\n",
        "    # traemos a la cpu\n",
        "    y_pred = y_pred.view(-1).to('cpu')\n",
        "    y_true = y_true.to('cpu')\n",
        "    \n",
        "    # calcular scores\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    return precision, recall, f1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hod516H1aSG2"
      },
      "source": [
        "-------------------\n",
        "\n",
        "### Modelo Baseline\n",
        "\n",
        "Teniendo ya cargado los datos, toca definir nuestro modelo. Este baseline tendrá una capa de embedding, unas cuantas LSTM y una capa de salida y usará dropout en el entrenamiento.\n",
        "\n",
        "Este constará de los siguientes pasos: \n",
        "\n",
        "1. Definir la clase que contendrá la red.\n",
        "2. Definir los hiperparámetros e inicializar la red. \n",
        "3. Definir la época de entrenamiento\n",
        "3. Definir la función de loss.\n",
        "\n",
        "\n",
        "\n",
        "Recomendamos que para experimentar, encapsules los modelos en una sola variable y luego la fijes en model para entrenarla"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.666751Z",
          "start_time": "2020-06-23T22:25:51.656778Z"
        },
        "colab_type": "code",
        "id": "rMPL08XqaSG3",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class NER_RNN(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim,\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=pad_idx)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T21:43:02.333880Z",
          "start_time": "2020-06-22T21:43:02.329861Z"
        },
        "colab_type": "text",
        "id": "cCl3530VaSG7"
      },
      "source": [
        "#### Hiperparámetros de la red\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdr8OzmVg-Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "    # Inicializamos los pesos como aleatorios\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean=0, std=0.1) \n",
        "        \n",
        "    # Seteamos como 0 los embeddings de UNK y PAD.\n",
        "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.705684Z",
          "start_time": "2020-06-23T22:25:51.668746Z"
        },
        "colab_type": "code",
        "id": "EHdi3QdOaSG8",
        "colab": {}
      },
      "source": [
        "# tamaño del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100  # dimensión de los embeddings.\n",
        "HIDDEN_DIM = 128  # dimensión de la capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)  # número de clases\n",
        "\n",
        "N_LAYERS = 2  # número de capas.\n",
        "DROPOUT = 0.25\n",
        "BIDIRECTIONAL = False\n",
        "\n",
        "# Creamos nuestro modelo.\n",
        "baseline_model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "baseline_model_name = 'baseline'  # nombre que tendrá el modelo guardado...\n",
        "baseline_n_epochs = 10\n",
        "\n",
        "# Loss: Cross Entropy\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
        "baseline_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.805380Z",
          "start_time": "2020-06-23T22:25:51.751524Z"
        },
        "colab_type": "code",
        "id": "Q-G_NWFcaSHe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "d87c2b60-5480-465b-a7ea-04407dafba1e"
      },
      "source": [
        "model = baseline_model\n",
        "model_name = baseline_model_name\n",
        "criterion = baseline_criterion\n",
        "n_epochs = baseline_n_epochs\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NER_RNN(\n",
              "  (embedding): Embedding(26101, 100, padding_idx=1)\n",
              "  (lstm): LSTM(100, 128, num_layers=2, dropout=0.25)\n",
              "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UVqBqerlaSHk"
      },
      "source": [
        "Por último, definimos los embeddings que representan a \\<unk\\> y \\<pad\\>  como [0, 0, ..., 0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiKRbZ7-6Q8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "9dec9cfb-45a1-4b13-d68e-fb6603f73e68"
      },
      "source": [
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs=10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01/10 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.438 | Train f1: 0.14 | Train precision: 0.17 | Train recall: 0.14\n",
            "\t Val. Loss: 0.312 |  Val. f1: 0.30 |  Val. precision: 0.38 | Val. recall: 0.29\n",
            "Epoch: 02/10 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.181 | Train f1: 0.45 | Train precision: 0.51 | Train recall: 0.45\n",
            "\t Val. Loss: 0.263 |  Val. f1: 0.45 |  Val. precision: 0.55 | Val. recall: 0.44\n",
            "Epoch: 03/10 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.108 | Train f1: 0.64 | Train precision: 0.68 | Train recall: 0.64\n",
            "\t Val. Loss: 0.226 |  Val. f1: 0.53 |  Val. precision: 0.60 | Val. recall: 0.53\n",
            "Epoch: 04/10 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.076 | Train f1: 0.73 | Train precision: 0.76 | Train recall: 0.73\n",
            "\t Val. Loss: 0.235 |  Val. f1: 0.56 |  Val. precision: 0.62 | Val. recall: 0.58\n",
            "Epoch: 05/10 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.056 | Train f1: 0.79 | Train precision: 0.81 | Train recall: 0.79\n",
            "\t Val. Loss: 0.233 |  Val. f1: 0.57 |  Val. precision: 0.64 | Val. recall: 0.57\n",
            "Epoch: 06/10 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.045 | Train f1: 0.82 | Train precision: 0.84 | Train recall: 0.82\n",
            "\t Val. Loss: 0.241 |  Val. f1: 0.57 |  Val. precision: 0.64 | Val. recall: 0.56\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.226 |  Val. f1: 0.53 | Val. precision: 0.60 | Val. recall: 0.53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9spX-Hkh8YJg"
      },
      "source": [
        "### Modelos\n",
        "\n",
        "*   **[DONE]** Probar Early stopping\n",
        "*   Variar la cantidad de parámetros de la capa de embeddings.\n",
        "*   **[DONE]** Variar la cantidad de capas RNN.\n",
        "*   Variar la cantidad de parámetros de las capas de RNN.\n",
        "*   Inicializar la capa de embeddings con modelos pre-entrenados. (word2vec, glove, conceptnet, etc...).[Guía breve aquí](https://github.com/dccuchile/spanish-word-embeddings), [Embeddings en español aquí](https://github.com/dccuchile/spanish-word-embeddings).\n",
        "*   **[DONE]** Variar la cantidad de épocas de entrenamiento.\n",
        "*   Variar el optimizador, learning rate, batch size, usar CRF loss, etc...\n",
        "*   **[DONE]** Probar bi-direccionalidad.\n",
        "*   Probar teacher forcing.\n",
        "*   **[DONE]** Incluir dropout.\n",
        "*   Probar modelos de tipo GRU\n",
        "*   Probar Embedding Contextuales (les puede ser de utilidad [flair](https://github.com/flairNLP/flair))\n",
        "*   Probar modelos de transformers en español usando [Huggingface](https://github.com/huggingface/transformers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lRYOEDiQaSHK"
      },
      "source": [
        "--------------------\n",
        "### Modelo 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.722604Z",
          "start_time": "2020-06-23T22:25:51.717615Z"
        },
        "colab_type": "code",
        "id": "c81f8ki5aSHL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "52761fc7-2ee1-4fc3-ef2a-edad28475b33"
      },
      "source": [
        "BIDIRECTIONAL = True\n",
        "model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX).apply(init_weights)\n",
        "\n",
        "model_name = 'bi_rnn'  # nombre que tendrá el modelo guardado\n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01/10 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.360 | Train f1: 0.26 | Train precision: 0.32 | Train recall: 0.25\n",
            "\t Val. Loss: 0.271 |  Val. f1: 0.43 |  Val. precision: 0.53 | Val. recall: 0.42\n",
            "Epoch: 02/10 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.125 | Train f1: 0.61 | Train precision: 0.66 | Train recall: 0.60\n",
            "\t Val. Loss: 0.207 |  Val. f1: 0.54 |  Val. precision: 0.62 | Val. recall: 0.54\n",
            "Epoch: 03/10 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.068 | Train f1: 0.75 | Train precision: 0.78 | Train recall: 0.75\n",
            "\t Val. Loss: 0.203 |  Val. f1: 0.58 |  Val. precision: 0.66 | Val. recall: 0.57\n",
            "Epoch: 04/10 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.044 | Train f1: 0.82 | Train precision: 0.84 | Train recall: 0.82\n",
            "\t Val. Loss: 0.195 |  Val. f1: 0.61 |  Val. precision: 0.67 | Val. recall: 0.61\n",
            "Epoch: 05/10 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.031 | Train f1: 0.86 | Train precision: 0.88 | Train recall: 0.86\n",
            "\t Val. Loss: 0.224 |  Val. f1: 0.61 |  Val. precision: 0.68 | Val. recall: 0.60\n",
            "Epoch: 06/10 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.023 | Train f1: 0.90 | Train precision: 0.91 | Train recall: 0.90\n",
            "\t Val. Loss: 0.254 |  Val. f1: 0.60 |  Val. precision: 0.67 | Val. recall: 0.59\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.195 |  Val. f1: 0.61 | Val. precision: 0.67 | Val. recall: 0.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rV9oLkN1aSHO"
      },
      "source": [
        "---------------\n",
        "\n",
        "### Modelo 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaMtZ5lrseP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "04feba2f-c0ef-4882-ba1b-09c16f166215"
      },
      "source": [
        "model = NER_RNN(input_dim=len(TEXT.vocab),\n",
        "                embedding_dim=100,\n",
        "                hidden_dim=200,\n",
        "                output_dim=len(NER_TAGS.vocab),\n",
        "                n_layers=3,\n",
        "                bidirectional=True,\n",
        "                dropout=0.2,\n",
        "                pad_idx=PAD_IDX).apply(init_weights)\n",
        "\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')\n",
        "\n",
        "model_name = 'bigger_bi_rnn'  # nombre que tendrá el modelo guardado\n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 5,023,710 parámetros entrenables.\n",
            "Epoch: 01/10 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.293 | Train f1: 0.32 | Train precision: 0.37 | Train recall: 0.33\n",
            "\t Val. Loss: 0.234 |  Val. f1: 0.48 |  Val. precision: 0.56 | Val. recall: 0.47\n",
            "Epoch: 02/10 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.111 | Train f1: 0.65 | Train precision: 0.69 | Train recall: 0.66\n",
            "\t Val. Loss: 0.231 |  Val. f1: 0.54 |  Val. precision: 0.63 | Val. recall: 0.54\n",
            "Epoch: 03/10 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.065 | Train f1: 0.77 | Train precision: 0.79 | Train recall: 0.77\n",
            "\t Val. Loss: 0.212 |  Val. f1: 0.59 |  Val. precision: 0.65 | Val. recall: 0.59\n",
            "Epoch: 04/10 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.050 | Train f1: 0.82 | Train precision: 0.84 | Train recall: 0.82\n",
            "\t Val. Loss: 0.223 |  Val. f1: 0.60 |  Val. precision: 0.66 | Val. recall: 0.61\n",
            "Epoch: 05/10 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.041 | Train f1: 0.84 | Train precision: 0.85 | Train recall: 0.84\n",
            "\t Val. Loss: 0.245 |  Val. f1: 0.60 |  Val. precision: 0.67 | Val. recall: 0.59\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.212 |  Val. f1: 0.59 | Val. precision: 0.65 | Val. recall: 0.59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRuPM9QlyxG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "b5734999-a25a-4cd9-c280-5dbb26b8d571"
      },
      "source": [
        "# glove pretrained embeddings\n",
        "!wget http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-27 01:09:08--  http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz\n",
            "Resolving dcc.uchile.cl (dcc.uchile.cl)... 192.80.24.11\n",
            "Connecting to dcc.uchile.cl (dcc.uchile.cl)|192.80.24.11|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz [following]\n",
            "--2020-07-27 01:09:09--  https://www.dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz\n",
            "Resolving www.dcc.uchile.cl (www.dcc.uchile.cl)... 192.80.24.11, 200.9.99.213\n",
            "Connecting to www.dcc.uchile.cl (www.dcc.uchile.cl)|192.80.24.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://users.dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz [following]\n",
            "--2020-07-27 01:09:10--  https://users.dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz\n",
            "Resolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 192.80.24.4, 200.9.99.211\n",
            "Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|192.80.24.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 949886421 (906M) [application/x-gzip]\n",
            "Saving to: ‘glove-sbwc.i25.vec.gz’\n",
            "\n",
            "glove-sbwc.i25.vec. 100%[===================>] 905.88M  7.35MB/s    in 2m 24s  \n",
            "\n",
            "2020-07-27 01:11:35 (6.29 MB/s) - ‘glove-sbwc.i25.vec.gz’ saved [949886421/949886421]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-22T16:07:45.755561Z",
          "start_time": "2020-06-22T16:07:45.751571Z"
        },
        "colab_type": "text",
        "id": "Zpy3p7YaaSHT"
      },
      "source": [
        "---------------\n",
        "\n",
        "\n",
        "### Modelo 3: Mayor batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2oCe4DrvkhT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e32aeb18-88c1-4499-a730-f9c895d47e88"
      },
      "source": [
        "BATCH_SIZE = 64  # disminuir si hay problemas de ram.\n",
        "\n",
        "# Usar cuda si es que está disponible.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "# Dividir datos entre entrenamiento y test\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort=False,\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.728587Z",
          "start_time": "2020-06-23T22:25:51.724596Z"
        },
        "colab_type": "code",
        "id": "KWPzETaNaSHP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "b0320f33-4410-459a-84ec-bbcd9a47f19f"
      },
      "source": [
        "model = NER_RNN(input_dim=len(TEXT.vocab),\n",
        "                embedding_dim=100,\n",
        "                hidden_dim=200,\n",
        "                output_dim=len(NER_TAGS.vocab),\n",
        "                n_layers=3,\n",
        "                bidirectional=True,\n",
        "                dropout=0.3,\n",
        "                pad_idx=PAD_IDX).apply(init_weights)\n",
        "\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')\n",
        "\n",
        "model_name = 'bigger_bi_rnn'  # nombre que tendrá el modelo guardado\n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 5,023,710 parámetros entrenables.\n",
            "Epoch: 01/10 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.554 | Train f1: 0.06 | Train precision: 0.09 | Train recall: 0.07\n",
            "\t Val. Loss: 0.316 |  Val. f1: 0.26 |  Val. precision: 0.28 | Val. recall: 0.30\n",
            "Epoch: 02/10 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.175 | Train f1: 0.46 | Train precision: 0.52 | Train recall: 0.46\n",
            "\t Val. Loss: 0.224 |  Val. f1: 0.52 |  Val. precision: 0.58 | Val. recall: 0.54\n",
            "Epoch: 03/10 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.093 | Train f1: 0.69 | Train precision: 0.72 | Train recall: 0.68\n",
            "\t Val. Loss: 0.201 |  Val. f1: 0.59 |  Val. precision: 0.66 | Val. recall: 0.58\n",
            "Epoch: 04/10 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.059 | Train f1: 0.77 | Train precision: 0.79 | Train recall: 0.77\n",
            "\t Val. Loss: 0.217 |  Val. f1: 0.64 |  Val. precision: 0.66 | Val. recall: 0.65\n",
            "Epoch: 05/10 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.044 | Train f1: 0.81 | Train precision: 0.82 | Train recall: 0.81\n",
            "\t Val. Loss: 0.226 |  Val. f1: 0.64 |  Val. precision: 0.68 | Val. recall: 0.65\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.201 |  Val. f1: 0.59 | Val. precision: 0.66 | Val. recall: 0.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN5Xuo9YwjOl",
        "colab_type": "text"
      },
      "source": [
        "---------------\n",
        "\n",
        "\n",
        "### Modelo 4: Agregar más capas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N7rqPJPtkPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NER_RNN2(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim, \n",
        "                 hidden_dim, \n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 bidirectional, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim,\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=pad_idx)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Sequential(nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                                          hidden_dim),\n",
        "                                # nn.BatchNorm1d(num_features=hidden_dim),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        # print(text.shape)\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        # print(embedded.shape)\n",
        "        \n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        # print(outputs.shape)\n",
        "\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:25:51.733572Z",
          "start_time": "2020-06-23T22:25:51.730580Z"
        },
        "colab_type": "code",
        "id": "_w0CFjA8aSHU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "63b2a4d9-a0a2-4c87-fe6a-cdcddb156e4f"
      },
      "source": [
        "model = NER_RNN2(input_dim=len(TEXT.vocab),\n",
        "                embedding_dim=100,\n",
        "                hidden_dim=200,\n",
        "                output_dim=len(NER_TAGS.vocab),\n",
        "                n_layers=3,\n",
        "                bidirectional=True,\n",
        "                dropout=0.3,\n",
        "                pad_idx=PAD_IDX).apply(init_weights)\n",
        "\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')\n",
        "\n",
        "model_name = 'bigger_bi_rnn'  # nombre que tendrá el modelo guardado\n",
        "n_epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "run_training(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El modelo actual tiene 5,101,910 parámetros entrenables.\n",
            "Epoch: 01/10 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.695 | Train f1: 0.00 | Train precision: 0.00 | Train recall: 0.00\n",
            "\t Val. Loss: 0.692 |  Val. f1: 0.00 |  Val. precision: 0.00 | Val. recall: 0.00\n",
            "Epoch: 02/10 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.310 | Train f1: 0.12 | Train precision: 0.15 | Train recall: 0.15\n",
            "\t Val. Loss: 0.310 |  Val. f1: 0.22 |  Val. precision: 0.26 | Val. recall: 0.24\n",
            "Epoch: 03/10 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.191 | Train f1: 0.32 | Train precision: 0.37 | Train recall: 0.35\n",
            "\t Val. Loss: 0.329 |  Val. f1: 0.37 |  Val. precision: 0.41 | Val. recall: 0.40\n",
            "Epoch: 04/10 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.135 | Train f1: 0.51 | Train precision: 0.53 | Train recall: 0.53\n",
            "\t Val. Loss: 0.272 |  Val. f1: 0.42 |  Val. precision: 0.47 | Val. recall: 0.45\n",
            "Epoch: 05/10 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.095 | Train f1: 0.67 | Train precision: 0.70 | Train recall: 0.67\n",
            "\t Val. Loss: 0.273 |  Val. f1: 0.55 |  Val. precision: 0.60 | Val. recall: 0.57\n",
            "------------------------------------------------\n",
            "---------------- BEST MODEL --------------------\n",
            "------------------------------------------------\n",
            "Val. Loss: 0.272 |  Val. f1: 0.42 | Val. precision: 0.47 | Val. recall: 0.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g5jzCzZ3C0q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a069d15f-557e-47be-ed29-4754f3900831"
      },
      "source": [
        "print(len(TEXT.vocab), len(NER_TAGS.vocab))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26101 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T21:52:04.077979Z",
          "start_time": "2020-06-23T21:52:04.072991Z"
        },
        "id": "9NNSdjcCzXzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Limpiar ram de cuda\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uF1ysw_Kw6zz"
      },
      "source": [
        "\n",
        "## Predecir datos para la competencia\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:31:56.776563Z",
          "start_time": "2020-06-23T22:31:39.654525Z"
        },
        "colab_type": "code",
        "id": "1RBs3UU4wLk3",
        "colab": {}
      },
      "source": [
        "def predict_labels(model, iterator, criterion, fields=fields):\n",
        "\n",
        "    # Extraemos los vocabularios.\n",
        "    text_field = fields[0][1]\n",
        "    nertags_field = fields[1][1]\n",
        "    tags_vocab = nertags_field.vocab.itos\n",
        "    words_vocab = text_field.vocab.itos\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            text_batch = batch.text\n",
        "            text_batch = torch.transpose(text_batch, 0, 1).tolist()\n",
        "\n",
        "            # Predecir los tags de las sentences del batch\n",
        "            predictions_batch = model(batch.text)\n",
        "            predictions_batch = torch.transpose(predictions_batch, 0, 1)\n",
        "\n",
        "            # por cada oración predicha:\n",
        "            for sentence, sentence_prediction in zip(text_batch,\n",
        "                                                     predictions_batch):\n",
        "                for word_idx, word_predictions in zip(sentence,\n",
        "                                                      sentence_prediction):\n",
        "                    # Obtener el indice del tag con la probabilidad mas alta.\n",
        "                    argmax_index = word_predictions.topk(1)[1]\n",
        "\n",
        "                    current_tag = tags_vocab[argmax_index]\n",
        "                    # Obtenemos la palabra\n",
        "                    current_word = words_vocab[word_idx]\n",
        "\n",
        "                    if current_word != '<pad>':\n",
        "                        predictions.append([current_word, current_tag])\n",
        "\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "predictions = predict_labels(model, test_iterator, criterion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YwQp1Ru8Oht8"
      },
      "source": [
        "### Generar el archivo para la submission\n",
        "\n",
        "No hay problema si aparecen unk en la salida. Estos no son relevantes para evaluarlos, usamos solo los tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T22:33:41.845955Z",
          "start_time": "2020-06-23T22:33:41.731717Z"
        },
        "colab_type": "code",
        "id": "RPfZkjJGkWyq",
        "colab": {}
      },
      "source": [
        "import os, shutil\n",
        "\n",
        "if (os.path.isfile('./predictions.zip')):\n",
        "    os.remove('./predictions.zip')\n",
        "\n",
        "if (not os.path.isdir('./predictions')):\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "else:\n",
        "    # Eliminar predicciones anteriores:\n",
        "    shutil.rmtree('./predictions')\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "f = open('predictions/predictions.txt', 'w')\n",
        "for word, tag in predictions:\n",
        "    f.write(word + ' ' + tag + '\\n')\n",
        "f.write('\\n')\n",
        "f.close()\n",
        "\n",
        "a = shutil.make_archive('predictions', 'zip', './predictions')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-06-23T21:49:19.575711Z",
          "start_time": "2020-06-23T21:49:19.100486Z"
        },
        "colab_type": "code",
        "id": "k2PqvJAmTFWR",
        "colab": {}
      },
      "source": [
        "# A veces no funciona a la primera. Ejecutar mas de una vez para obtener el archivo...\n",
        "from google.colab import files\n",
        "files.download('predictions.zip')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LZEWJXrNaSIf"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "\n",
        "\n",
        "..."
      ]
    }
  ]
}